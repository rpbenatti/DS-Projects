{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP - NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AbstractLazySequence',\n",
       " 'AffixTagger',\n",
       " 'AlignedSent',\n",
       " 'Alignment',\n",
       " 'AnnotationTask',\n",
       " 'ApplicationExpression',\n",
       " 'Assignment',\n",
       " 'BigramAssocMeasures',\n",
       " 'BigramCollocationFinder',\n",
       " 'BigramTagger',\n",
       " 'BinaryMaxentFeatureEncoding',\n",
       " 'BlanklineTokenizer',\n",
       " 'BllipParser',\n",
       " 'BottomUpChartParser',\n",
       " 'BottomUpLeftCornerChartParser',\n",
       " 'BottomUpProbabilisticChartParser',\n",
       " 'Boxer',\n",
       " 'BrillTagger',\n",
       " 'BrillTaggerTrainer',\n",
       " 'CFG',\n",
       " 'CRFTagger',\n",
       " 'CfgReadingCommand',\n",
       " 'ChartParser',\n",
       " 'ChunkParserI',\n",
       " 'ChunkScore',\n",
       " 'Cistem',\n",
       " 'ClassifierBasedPOSTagger',\n",
       " 'ClassifierBasedTagger',\n",
       " 'ClassifierI',\n",
       " 'ConcordanceIndex',\n",
       " 'ConditionalExponentialClassifier',\n",
       " 'ConditionalFreqDist',\n",
       " 'ConditionalProbDist',\n",
       " 'ConditionalProbDistI',\n",
       " 'ConfusionMatrix',\n",
       " 'ContextIndex',\n",
       " 'ContextTagger',\n",
       " 'ContingencyMeasures',\n",
       " 'CoreNLPDependencyParser',\n",
       " 'CoreNLPParser',\n",
       " 'Counter',\n",
       " 'CrossValidationProbDist',\n",
       " 'DRS',\n",
       " 'DecisionTreeClassifier',\n",
       " 'DefaultTagger',\n",
       " 'DependencyEvaluator',\n",
       " 'DependencyGrammar',\n",
       " 'DependencyGraph',\n",
       " 'DependencyProduction',\n",
       " 'DictionaryConditionalProbDist',\n",
       " 'DictionaryProbDist',\n",
       " 'DiscourseTester',\n",
       " 'DrtExpression',\n",
       " 'DrtGlueReadingCommand',\n",
       " 'ELEProbDist',\n",
       " 'EarleyChartParser',\n",
       " 'Expression',\n",
       " 'FStructure',\n",
       " 'FeatDict',\n",
       " 'FeatList',\n",
       " 'FeatStruct',\n",
       " 'FeatStructReader',\n",
       " 'Feature',\n",
       " 'FeatureBottomUpChartParser',\n",
       " 'FeatureBottomUpLeftCornerChartParser',\n",
       " 'FeatureChartParser',\n",
       " 'FeatureEarleyChartParser',\n",
       " 'FeatureIncrementalBottomUpChartParser',\n",
       " 'FeatureIncrementalBottomUpLeftCornerChartParser',\n",
       " 'FeatureIncrementalChartParser',\n",
       " 'FeatureIncrementalTopDownChartParser',\n",
       " 'FeatureTopDownChartParser',\n",
       " 'FreqDist',\n",
       " 'HTTPPasswordMgrWithDefaultRealm',\n",
       " 'HeldoutProbDist',\n",
       " 'HiddenMarkovModelTagger',\n",
       " 'HiddenMarkovModelTrainer',\n",
       " 'HunposTagger',\n",
       " 'IBMModel',\n",
       " 'IBMModel1',\n",
       " 'IBMModel2',\n",
       " 'IBMModel3',\n",
       " 'IBMModel4',\n",
       " 'IBMModel5',\n",
       " 'ISRIStemmer',\n",
       " 'ImmutableMultiParentedTree',\n",
       " 'ImmutableParentedTree',\n",
       " 'ImmutableProbabilisticMixIn',\n",
       " 'ImmutableProbabilisticTree',\n",
       " 'ImmutableTree',\n",
       " 'IncrementalBottomUpChartParser',\n",
       " 'IncrementalBottomUpLeftCornerChartParser',\n",
       " 'IncrementalChartParser',\n",
       " 'IncrementalLeftCornerChartParser',\n",
       " 'IncrementalTopDownChartParser',\n",
       " 'Index',\n",
       " 'InsideChartParser',\n",
       " 'JSONTaggedDecoder',\n",
       " 'JSONTaggedEncoder',\n",
       " 'KneserNeyProbDist',\n",
       " 'LancasterStemmer',\n",
       " 'LaplaceProbDist',\n",
       " 'LazyConcatenation',\n",
       " 'LazyEnumerate',\n",
       " 'LazyIteratorList',\n",
       " 'LazyMap',\n",
       " 'LazySubsequence',\n",
       " 'LazyZip',\n",
       " 'LeftCornerChartParser',\n",
       " 'LidstoneProbDist',\n",
       " 'LineTokenizer',\n",
       " 'LogicalExpressionException',\n",
       " 'LongestChartParser',\n",
       " 'MLEProbDist',\n",
       " 'MWETokenizer',\n",
       " 'Mace',\n",
       " 'MaceCommand',\n",
       " 'MaltParser',\n",
       " 'MaxentClassifier',\n",
       " 'Model',\n",
       " 'MultiClassifierI',\n",
       " 'MultiParentedTree',\n",
       " 'MutableProbDist',\n",
       " 'NaiveBayesClassifier',\n",
       " 'NaiveBayesDependencyScorer',\n",
       " 'NgramAssocMeasures',\n",
       " 'NgramTagger',\n",
       " 'NonprojectiveDependencyParser',\n",
       " 'Nonterminal',\n",
       " 'OrderedDict',\n",
       " 'PCFG',\n",
       " 'Paice',\n",
       " 'ParallelProverBuilder',\n",
       " 'ParallelProverBuilderCommand',\n",
       " 'ParentedTree',\n",
       " 'ParserI',\n",
       " 'PerceptronTagger',\n",
       " 'PhraseTable',\n",
       " 'PorterStemmer',\n",
       " 'PositiveNaiveBayesClassifier',\n",
       " 'ProbDistI',\n",
       " 'ProbabilisticDependencyGrammar',\n",
       " 'ProbabilisticMixIn',\n",
       " 'ProbabilisticNonprojectiveParser',\n",
       " 'ProbabilisticProduction',\n",
       " 'ProbabilisticProjectiveDependencyParser',\n",
       " 'ProbabilisticTree',\n",
       " 'Production',\n",
       " 'ProjectiveDependencyParser',\n",
       " 'Prover9',\n",
       " 'Prover9Command',\n",
       " 'ProxyBasicAuthHandler',\n",
       " 'ProxyDigestAuthHandler',\n",
       " 'ProxyHandler',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'QuadgramAssocMeasures',\n",
       " 'QuadgramCollocationFinder',\n",
       " 'RSLPStemmer',\n",
       " 'RTEFeatureExtractor',\n",
       " 'RUS_PICKLE',\n",
       " 'RandomChartParser',\n",
       " 'RangeFeature',\n",
       " 'ReadingCommand',\n",
       " 'RecursiveDescentParser',\n",
       " 'RegexpChunkParser',\n",
       " 'RegexpParser',\n",
       " 'RegexpStemmer',\n",
       " 'RegexpTagger',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'ResolutionProver',\n",
       " 'ResolutionProverCommand',\n",
       " 'SExprTokenizer',\n",
       " 'SLASH',\n",
       " 'Senna',\n",
       " 'SennaChunkTagger',\n",
       " 'SennaNERTagger',\n",
       " 'SennaTagger',\n",
       " 'SequentialBackoffTagger',\n",
       " 'ShiftReduceParser',\n",
       " 'SimpleGoodTuringProbDist',\n",
       " 'SklearnClassifier',\n",
       " 'SlashFeature',\n",
       " 'SnowballStemmer',\n",
       " 'SpaceTokenizer',\n",
       " 'StackDecoder',\n",
       " 'StanfordNERTagger',\n",
       " 'StanfordPOSTagger',\n",
       " 'StanfordSegmenter',\n",
       " 'StanfordTagger',\n",
       " 'StemmerI',\n",
       " 'SteppingChartParser',\n",
       " 'SteppingRecursiveDescentParser',\n",
       " 'SteppingShiftReduceParser',\n",
       " 'SyllableTokenizer',\n",
       " 'TYPE',\n",
       " 'TabTokenizer',\n",
       " 'TableauProver',\n",
       " 'TableauProverCommand',\n",
       " 'TaggerI',\n",
       " 'TestGrammar',\n",
       " 'Text',\n",
       " 'TextCat',\n",
       " 'TextCollection',\n",
       " 'TextTilingTokenizer',\n",
       " 'TnT',\n",
       " 'TokenSearcher',\n",
       " 'ToktokTokenizer',\n",
       " 'TopDownChartParser',\n",
       " 'TransitionParser',\n",
       " 'Tree',\n",
       " 'TreebankWordTokenizer',\n",
       " 'Trie',\n",
       " 'TrigramAssocMeasures',\n",
       " 'TrigramCollocationFinder',\n",
       " 'TrigramTagger',\n",
       " 'TweetTokenizer',\n",
       " 'TypedMaxentFeatureEncoding',\n",
       " 'Undefined',\n",
       " 'UniformProbDist',\n",
       " 'UnigramTagger',\n",
       " 'UnsortedChartParser',\n",
       " 'Valuation',\n",
       " 'Variable',\n",
       " 'ViterbiParser',\n",
       " 'WekaClassifier',\n",
       " 'WhitespaceTokenizer',\n",
       " 'WittenBellProbDist',\n",
       " 'WordNetLemmatizer',\n",
       " 'WordPunctTokenizer',\n",
       " '__author__',\n",
       " '__author_email__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__classifiers__',\n",
       " '__copyright__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__keywords__',\n",
       " '__license__',\n",
       " '__loader__',\n",
       " '__longdescr__',\n",
       " '__maintainer__',\n",
       " '__maintainer_email__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__url__',\n",
       " '__version__',\n",
       " 'absolute_import',\n",
       " 'accuracy',\n",
       " 'add_logs',\n",
       " 'agreement',\n",
       " 'align',\n",
       " 'alignment_error_rate',\n",
       " 'aline',\n",
       " 'api',\n",
       " 'app',\n",
       " 'apply_features',\n",
       " 'approxrand',\n",
       " 'arity',\n",
       " 'association',\n",
       " 'bigrams',\n",
       " 'binary_distance',\n",
       " 'binary_search_file',\n",
       " 'binding_ops',\n",
       " 'bisect',\n",
       " 'blankline_tokenize',\n",
       " 'bleu',\n",
       " 'bleu_score',\n",
       " 'bllip',\n",
       " 'boolean_ops',\n",
       " 'boxer',\n",
       " 'bracket_parse',\n",
       " 'breadth_first',\n",
       " 'brill',\n",
       " 'brill_trainer',\n",
       " 'build_opener',\n",
       " 'call_megam',\n",
       " 'casual',\n",
       " 'casual_tokenize',\n",
       " 'ccg',\n",
       " 'chain',\n",
       " 'chart',\n",
       " 'chat',\n",
       " 'choose',\n",
       " 'chunk',\n",
       " 'cistem',\n",
       " 'class_types',\n",
       " 'classify',\n",
       " 'clause',\n",
       " 'clean_html',\n",
       " 'clean_url',\n",
       " 'cluster',\n",
       " 'collections',\n",
       " 'collocations',\n",
       " 'combinations',\n",
       " 'compat',\n",
       " 'config_java',\n",
       " 'config_megam',\n",
       " 'config_weka',\n",
       " 'conflicts',\n",
       " 'confusionmatrix',\n",
       " 'conllstr2tree',\n",
       " 'conlltags2tree',\n",
       " 'corenlp',\n",
       " 'corpus',\n",
       " 'crf',\n",
       " 'custom_distance',\n",
       " 'data',\n",
       " 'decisiontree',\n",
       " 'decorator',\n",
       " 'decorators',\n",
       " 'defaultdict',\n",
       " 'demo',\n",
       " 'dependencygraph',\n",
       " 'deque',\n",
       " 'discourse',\n",
       " 'distance',\n",
       " 'download',\n",
       " 'download_gui',\n",
       " 'download_shell',\n",
       " 'downloader',\n",
       " 'draw',\n",
       " 'drt',\n",
       " 'earleychart',\n",
       " 'edit_distance',\n",
       " 'edit_distance_align',\n",
       " 'elementtree_indent',\n",
       " 'entropy',\n",
       " 'equality_preds',\n",
       " 'evaluate',\n",
       " 'evaluate_sents',\n",
       " 'everygrams',\n",
       " 'extract_rels',\n",
       " 'extract_test_sentences',\n",
       " 'f_measure',\n",
       " 'featstruct',\n",
       " 'featurechart',\n",
       " 'filestring',\n",
       " 'find',\n",
       " 'flatten',\n",
       " 'fractional_presence',\n",
       " 'getproxies',\n",
       " 'ghd',\n",
       " 'glue',\n",
       " 'grammar',\n",
       " 'guess_encoding',\n",
       " 'help',\n",
       " 'hmm',\n",
       " 'hunpos',\n",
       " 'ibm1',\n",
       " 'ibm2',\n",
       " 'ibm3',\n",
       " 'ibm4',\n",
       " 'ibm5',\n",
       " 'ibm_model',\n",
       " 'ieerstr2tree',\n",
       " 'improved_close_quote_regex',\n",
       " 'improved_open_quote_regex',\n",
       " 'improved_open_single_quote_regex',\n",
       " 'improved_punct_regex',\n",
       " 'in_idle',\n",
       " 'induce_pcfg',\n",
       " 'inference',\n",
       " 'infile',\n",
       " 'inspect',\n",
       " 'install_opener',\n",
       " 'internals',\n",
       " 'interpret_sents',\n",
       " 'interval_distance',\n",
       " 'invert_dict',\n",
       " 'invert_graph',\n",
       " 'is_rel',\n",
       " 'islice',\n",
       " 'isri',\n",
       " 'jaccard_distance',\n",
       " 'json_tags',\n",
       " 'jsontags',\n",
       " 'lancaster',\n",
       " 'lazyimport',\n",
       " 'lfg',\n",
       " 'line_tokenize',\n",
       " 'linearlogic',\n",
       " 'lm',\n",
       " 'load',\n",
       " 'load_parser',\n",
       " 'locale',\n",
       " 'log_likelihood',\n",
       " 'logic',\n",
       " 'mace',\n",
       " 'malt',\n",
       " 'map_tag',\n",
       " 'mapping',\n",
       " 'masi_distance',\n",
       " 'maxent',\n",
       " 'megam',\n",
       " 'memoize',\n",
       " 'meteor',\n",
       " 'meteor_score',\n",
       " 'metrics',\n",
       " 'misc',\n",
       " 'mwe',\n",
       " 'naivebayes',\n",
       " 'ne_chunk',\n",
       " 'ne_chunk_sents',\n",
       " 'ngrams',\n",
       " 'nonprojectivedependencyparser',\n",
       " 'nonterminals',\n",
       " 'numpy',\n",
       " 'os',\n",
       " 'pad_sequence',\n",
       " 'paice',\n",
       " 'parse',\n",
       " 'parse_sents',\n",
       " 'pchart',\n",
       " 'perceptron',\n",
       " 'pk',\n",
       " 'porter',\n",
       " 'pos_tag',\n",
       " 'pos_tag_sents',\n",
       " 'positivenaivebayes',\n",
       " 'pprint',\n",
       " 'pr',\n",
       " 'precision',\n",
       " 'presence',\n",
       " 'print_function',\n",
       " 'print_string',\n",
       " 'probability',\n",
       " 'projectivedependencyparser',\n",
       " 'prover9',\n",
       " 'punkt',\n",
       " 'py25',\n",
       " 'py26',\n",
       " 'py27',\n",
       " 'pydoc',\n",
       " 'python_2_unicode_compatible',\n",
       " 'raise_unorderable_types',\n",
       " 'ranks_from_scores',\n",
       " 'ranks_from_sequence',\n",
       " 're',\n",
       " 're_show',\n",
       " 'read_grammar',\n",
       " 'read_logic',\n",
       " 'read_valuation',\n",
       " 'recall',\n",
       " 'recursivedescent',\n",
       " 'regexp',\n",
       " 'regexp_span_tokenize',\n",
       " 'regexp_tokenize',\n",
       " 'register_tag',\n",
       " 'relextract',\n",
       " 'repp',\n",
       " 'resolution',\n",
       " 'ribes',\n",
       " 'ribes_score',\n",
       " 'root_semrep',\n",
       " 'rslp',\n",
       " 'rte_classifier',\n",
       " 'rte_classify',\n",
       " 'rte_features',\n",
       " 'rtuple',\n",
       " 'scikitlearn',\n",
       " 'scores',\n",
       " 'segmentation',\n",
       " 'sem',\n",
       " 'senna',\n",
       " 'sent_tokenize',\n",
       " 'sequential',\n",
       " 'set2rel',\n",
       " 'set_proxy',\n",
       " 'sexpr',\n",
       " 'sexpr_tokenize',\n",
       " 'shiftreduce',\n",
       " 'simple',\n",
       " 'sinica_parse',\n",
       " 'skipgrams',\n",
       " 'skolemize',\n",
       " 'slice_bounds',\n",
       " 'snowball',\n",
       " 'sonority_sequencing',\n",
       " 'spearman',\n",
       " 'spearman_correlation',\n",
       " 'stack_decoder',\n",
       " 'stanford',\n",
       " 'stanford_segmenter',\n",
       " 'stem',\n",
       " 'str2tuple',\n",
       " 'string_span_tokenize',\n",
       " 'string_types',\n",
       " 'subprocess',\n",
       " 'subsumes',\n",
       " 'sum_logs',\n",
       " 'sys',\n",
       " 'tableau',\n",
       " 'tadm',\n",
       " 'tag',\n",
       " 'tagset_mapping',\n",
       " 'tagstr2tree',\n",
       " 'tbl',\n",
       " 'text',\n",
       " 'text_type',\n",
       " 'textcat',\n",
       " 'texttiling',\n",
       " 'textwrap',\n",
       " 'tkinter',\n",
       " 'tnt',\n",
       " 'tokenize',\n",
       " 'tokenwrap',\n",
       " 'toktok',\n",
       " 'toolbox',\n",
       " 'total_ordering',\n",
       " 'transitionparser',\n",
       " 'transitive_closure',\n",
       " 'translate',\n",
       " 'tree',\n",
       " 'tree2conllstr',\n",
       " 'tree2conlltags',\n",
       " 'treebank',\n",
       " 'treetransforms',\n",
       " 'trigrams',\n",
       " 'tuple2str',\n",
       " 'types',\n",
       " 'unify',\n",
       " 'unique_list',\n",
       " 'untag',\n",
       " 'usage',\n",
       " 'util',\n",
       " 'version_file',\n",
       " 'version_info',\n",
       " 'viterbi',\n",
       " 'weka',\n",
       " 'windowdiff',\n",
       " 'word_tokenize',\n",
       " 'wordnet',\n",
       " 'wordpunct_tokenize',\n",
       " 'wsd']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am learning NLP and using NLTK\n",
      "['I', 'am', 'learning', 'NLP', 'and', 'using', 'NLTK']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "input_txt = \"I am learning NLP and using NLTK\"\n",
    "word_tokens = word_tokenize(input_txt)\n",
    "print(input_txt)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Raw Text (reading raw data)\n",
    "- Tokenization (text to words)\n",
    "- Text Cleaning (removing punctuation and stop words, stemming)\n",
    "- Vectorization (word2vec, bag of words, tf-idf)\n",
    "- ML Algorithm \n",
    "- Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Text - Reading Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: open()  and  .read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\\nham\\tOk lar... Joking wif u oni...\\nspam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\nham\\tU dun say so early hor... U c already then say...\\nham\\tNah I don't think he goes to usf, he lives around here though\\nspam\\tFreeMsg Hey there darling it's been 3 week's now and no word bac\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = open('../Datasets/SMSSpamCollection').read()\n",
    "raw_data[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham',\n",
       " 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 'ham',\n",
       " 'Ok lar... Joking wif u oni...',\n",
       " 'spam',\n",
       " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       " 'ham',\n",
       " 'U dun say so early hor... U c already then say...',\n",
       " 'ham',\n",
       " \"Nah I don't think he goes to usf, he lives around here though\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_data = raw_data.replace('\\t','\\n').split('\\n')\n",
    "parsed_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham', 'ham', 'spam', 'ham', 'ham']\n",
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'Ok lar... Joking wif u oni...', \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'U dun say so early hor... U c already then say...', \"Nah I don't think he goes to usf, he lives around here though\"]\n"
     ]
    }
   ],
   "source": [
    "label_list = parsed_data[0::2]\n",
    "msg_list = parsed_data[1::2]\n",
    "print(label_list[0:5])\n",
    "print(msg_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5575\n",
      "5574\n",
      "['ham', 'ham', '']\n"
     ]
    }
   ],
   "source": [
    "print(len(label_list))\n",
    "print(len(msg_list))\n",
    "print(label_list[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined_df = pd.DataFrame({\n",
    "    'label' : label_list[:-1],\n",
    "    'sms' : msg_list\n",
    "})\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Datasets/SMSSpamCollection', sep='\\t', header=None)\n",
    "data.columns = ['label', 'sms']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data has 5572 rows, 2 columns\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input data has {len(data)} rows, {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham = 4825\n",
      "spam = 747\n"
     ]
    }
   ],
   "source": [
    "print(f\"ham = {len(data[data['label'] == 'ham'])}\")\n",
    "print(f\"spam = {len(data[data['label'] == 'spam'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of missing label = 0\n",
      "Numbers of missing msg = 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numbers of missing label = {data['label'].isnull().sum()}\")\n",
    "print(f\"Numbers of missing msg = {data['sms'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-processing (Tokenization + Text Cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove Punctuation\n",
    "- Tokenization\n",
    "- Remove stop words\n",
    "- Stemming/Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unnecessary characters.\n",
    "\n",
    "We will make use of the \"**string.punctuation**\" library for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "data.columns = ['label', 'msg']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"I am teaching NLP\" == \"I am teaching NLP.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(txt):\n",
    "    txt_nopunct = \"\".join([c for c in txt if c not in string.punctuation])\n",
    "    return txt_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                             msg_clean  \n",
       "0  Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...  \n",
       "1                                                                              Ok lar Joking wif u oni  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...  \n",
       "3                                                          U dun say so early hor U c already then say  \n",
       "4                                          Nah I dont think he goes to usf he lives around here though  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['msg_clean'] = data['msg'].apply(lambda x: remove_punctuation(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split text into list of words / tokens.\n",
    "\n",
    "We will make use of the regular expression \"**re**\" library for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_clean</th>\n",
       "      <th>msg_clean_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, then, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                             msg_clean  \\\n",
       "0  Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...   \n",
       "1                                                                              Ok lar Joking wif u oni   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
       "3                                                          U dun say so early hor U c already then say   \n",
       "4                                          Nah I dont think he goes to usf he lives around here though   \n",
       "\n",
       "                                                                                   msg_clean_tokenized  \n",
       "0  [go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, ci...  \n",
       "1                                                                       [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...  \n",
       "3                                              [u, dun, say, so, early, hor, u, c, already, then, say]  \n",
       "4                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(txt):\n",
    "    tokens = re.split('\\W+', txt)\n",
    "    return tokens\n",
    "\n",
    "data['msg_clean_tokenized'] = data['msg_clean'].apply(lambda x: tokenize(x.lower()))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of commonly used words which do not add much meaning.\n",
    "\n",
    "By removing extra stop words, we are giving very less words to our python algorithm to work with, thus speeding it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_clean</th>\n",
       "      <th>msg_clean_tokenized</th>\n",
       "      <th>msg_no_sw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, ci...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, then, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                             msg_clean  \\\n",
       "0  Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amo...   \n",
       "1                                                                              Ok lar Joking wif u oni   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
       "3                                                          U dun say so early hor U c already then say   \n",
       "4                                          Nah I dont think he goes to usf he lives around here though   \n",
       "\n",
       "                                                                                   msg_clean_tokenized  \\\n",
       "0  [go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, ci...   \n",
       "1                                                                       [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...   \n",
       "3                                              [u, dun, say, so, early, hor, u, c, already, then, say]   \n",
       "4                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]   \n",
       "\n",
       "                                                                                             msg_no_sw  \n",
       "0  [go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]  \n",
       "1                                                                       [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
       "3                                                        [u, dun, say, early, hor, u, c, already, say]  \n",
       "4                                                 [nah, dont, think, goes, usf, lives, around, though]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(txt_tokenized):\n",
    "    txt_clean = [word for word in txt_tokenized if word not in stopwords]\n",
    "    return txt_clean\n",
    "\n",
    "data['msg_no_sw'] = data['msg_clean_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is Stemming?**\n",
    "\n",
    "Stemming is a powerful tool to reduce the size of corpus that the model needs to work on.   \n",
    "Explicitly correlates words with similar meaning.\n",
    "\n",
    "It is a process of reducing inflected (or derived) words to their root word or word stem.\n",
    "\n",
    "Ex.\n",
    "\n",
    "code   \n",
    "coder   \n",
    "coders   \n",
    "coding   \n",
    "\n",
    "All are derived from \"**code**\"\n",
    "\n",
    "Since it is based in heuristics it is not a perfect rule that converts every word correctly to their stem word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Errors in Stemming**\n",
    "\n",
    "**1) Overstemming**\n",
    "\n",
    "- Too much of word is cut off (meaning lost)\n",
    "- 2 words of different stems reduced to same stem\n",
    "\n",
    "Ex.\n",
    "\n",
    "university   \n",
    "universities\n",
    "\n",
    "universal   \n",
    "universe\n",
    "\n",
    "They all could be converted to the same stem \"**univers** ...   \n",
    "while it would be better the first two be stemmed to \"**universi**\" and the second two words be stemmed to \"**univers**\"\n",
    "\n",
    "**2) Understemming**\n",
    "\n",
    "- 2 words of same stem mapped to different stems\n",
    "\n",
    "Ex.\n",
    "\n",
    "data  \n",
    "datum\n",
    "\n",
    "In this case, the first word is mapped or reduced to \"**dat**\" and the other to \"**datu**\"\".   \n",
    "So it has broken down into two different stems, although both should have been mapped to a common stem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming Algorithms**\n",
    "\n",
    "There are several stemming algorithms, but these ones are included in the NLTK toolkit package.\n",
    "\n",
    "- Porter Stemmer (most popular)\n",
    "- Snowball Stemmer\n",
    "- Lancaster Stemmer\n",
    "- Regex-based Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MARTIN_EXTENSIONS',\n",
       " 'NLTK_EXTENSIONS',\n",
       " 'ORIGINAL_ALGORITHM',\n",
       " '__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_apply_rule_list',\n",
       " '_contains_vowel',\n",
       " '_ends_cvc',\n",
       " '_ends_double_consonant',\n",
       " '_has_positive_measure',\n",
       " '_is_consonant',\n",
       " '_measure',\n",
       " '_replace_suffix',\n",
       " '_step1a',\n",
       " '_step1b',\n",
       " '_step1c',\n",
       " '_step2',\n",
       " '_step3',\n",
       " '_step4',\n",
       " '_step5a',\n",
       " '_step5b',\n",
       " 'mode',\n",
       " 'pool',\n",
       " 'stem',\n",
       " 'unicode_repr',\n",
       " 'vowels']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "dir(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coder\n",
      "code\n",
      "code\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('coder'))\n",
    "print(ps.stem('coding'))\n",
    "print(ps.stem('code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "datum\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('data'))\n",
    "print(ps.stem('datum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bowl\n",
      "bowl\n",
      "bowler\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('bowl'))\n",
    "print(ps.stem('bowling'))\n",
    "print(ps.stem('bowler'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Datasets/SMSSpamCollection', sep='\\t', header=None)\n",
    "data.columns = ['label', 'msg']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [word for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            msg_nostop  \n",
       "0  [go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]  \n",
       "1                                                                       [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
       "3                                                        [u, dun, say, early, hor, u, c, already, say]  \n",
       "4                                                 [nah, dont, think, goes, usf, lives, around, though]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['msg_nostop'] = data['msg'].apply(lambda x: clean_text(x.lower()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stem the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_nostop</th>\n",
       "      <th>msg_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            msg_nostop  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]   \n",
       "1                                                                       [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...   \n",
       "3                                                        [u, dun, say, early, hor, u, c, already, say]   \n",
       "4                                                 [nah, dont, think, goes, usf, lives, around, though]   \n",
       "\n",
       "                                                                                           msg_stemmed  \n",
       "0        [go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]  \n",
       "1                                                                         [ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...  \n",
       "3                                                        [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4                                                   [nah, dont, think, goe, usf, live, around, though]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['msg_stemmed'] = data['msg_nostop'].apply(lambda x: stemming(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular Normalization algorithm for words that is called Lemmatization.\n",
    "\n",
    "- Process of grouping together the inflected forms of a word to be analyzed as a single root word or ***lemma***\n",
    "- Unlike Stemming, it reduces the inflected words properly ensuring that the root word (***lemma***)  belongs to the language\n",
    "- A ***lemma*** is the canonical form, dictionary form, or citation form of a set of words\n",
    "- It is slower than Stemming but it is more accurate\n",
    "\n",
    "Ex.\n",
    "\n",
    "bowl   \n",
    "bowled   \n",
    "bowling   \n",
    "\n",
    "convert to ***bowl***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization vs Stemming**\n",
    "\n",
    "- Speed vs Accuracy tradeoff\n",
    "\n",
    "\n",
    "- ***Stemming*** is typically faster   \n",
    "  - simply chops off the end of a word using heuristics   \n",
    "  - no understanding of the context\n",
    "   \n",
    "\n",
    "- ***Lemmatization*** is typically more accurate\n",
    "  - Uses more informed analysis   \n",
    "  - Always reduce to a dictionary word   \n",
    "  - More accurate but computationally expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " 'lemmatize',\n",
       " 'unicode_repr']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "dir(wn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goos\n",
      "gees\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('goose'))\n",
    "print(ps.stem('geese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cactu\n",
      "cacti\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('cactus'))\n",
    "print(ps.stem('cacti'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goose\n",
      "goose\n"
     ]
    }
   ],
   "source": [
    "print(wn.lemmatize('goose'))\n",
    "print(wn.lemmatize('geese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cactus\n",
      "cactus\n"
     ]
    }
   ],
   "source": [
    "print(wn.lemmatize('cactus'))\n",
    "print(wn.lemmatize('cacti'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Datasets/SMSSpamCollection', sep='\\t', header=None)\n",
    "data.columns = ['label', 'msg']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            msg_nostop  \n",
       "0  [go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]  \n",
       "1                                                                       [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
       "3                                                        [u, dun, say, early, hor, u, c, already, say]  \n",
       "4                                                 [nah, dont, think, goes, usf, lives, around, though]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['msg_nostop'] = data['msg'].apply(lambda x: clean_text(x.lower()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_nostop</th>\n",
       "      <th>msg_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            msg_nostop  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]   \n",
       "1                                                                       [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...   \n",
       "3                                                        [u, dun, say, early, hor, u, c, already, say]   \n",
       "4                                                 [nah, dont, think, goes, usf, lives, around, though]   \n",
       "\n",
       "                                                                                        msg_lemmatized  \n",
       "0  [go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]  \n",
       "1                                                                       [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
       "3                                                        [u, dun, say, early, hor, u, c, already, say]  \n",
       "4                                                    [nah, dont, think, go, usf, life, around, though]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['msg_lemmatized'] = data['msg_nostop'].apply(lambda x: lemmatization(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to represent each of the words / tokens as numerical feature vectors?\n",
    "\n",
    "Vectorization is the process of encoding text as integers to create Feature Vectors.\n",
    "\n",
    "***Feature Vectors***: vector of numerical features that represent an object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of Vectorization**\n",
    "\n",
    "- CountVectorization\n",
    "- N-grams\n",
    "- TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the simplest choice of the existing vectorization techniques, which counts the words appearing in a document and hence creates a document-term matrix.   \n",
    "\n",
    "\n",
    "Note that the document needs to be handled from raw text format (cleaned, punctuation and stop words removed, tokenized, stemmed/lemmatized, etc).   \n",
    "\n",
    "\n",
    "Then from the list of words of the documents, we extract all the unique words and then count how many times they have occurred in the entire text corpus and write the corresponding frequencies in each document. So this will create the document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 6, 'is': 3, 'sentence': 4, 'another': 0, 'third': 5, 'document': 1, 'here': 2}\n",
      "['another', 'document', 'here', 'is', 'sentence', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "corpus = [\"This is a sentence is\",\n",
    "         \"This is another sentence\",\n",
    "         \"third document is here\"]\n",
    "\n",
    "X = cv.fit(corpus)\n",
    "print(X.vocabulary_)\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it sorts in alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 7)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 3)\t2\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 6)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 5)\t1\n",
      "[[0 0 0 2 1 0 1]\n",
      " [1 0 0 1 1 0 1]\n",
      " [0 1 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "X = cv.transform(corpus)\n",
    "# X = cv.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "print(type(X)) # Sparse matrix\n",
    "print(X)\n",
    "print(X.toarray()) # to print in the matrix form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   another  document  here  is  sentence  third  this\n",
      "0        0         0     0   2         1      0     1\n",
      "1        1         0     0   1         1      0     1\n",
      "2        0         1     1   1         0      1     0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(X.toarray(), columns = cv.get_feature_names())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorization on SMSSpamCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customizing it for the SMSSpamCollection dataset.\n",
    "\n",
    "Building the whole Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Raw Text\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv('../Datasets/SMSSpamCollection', sep='\\t', header=None)\n",
    "data.columns = ['label', 'msg']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Cleaning\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([c for c in text if c not in string.punctuation])   # remove punctuation\n",
    "    tokens = re.split('\\W+', text)                                     # tokenize\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords] # remove stopwords and apply Porter Stemming\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8340)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define an analyzer instead of the default one\n",
    "cv1 = CountVectorizer(analyzer=clean_text)\n",
    "\n",
    "X = cv1.fit_transform(data['msg'])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '0', '008704050406', '0089mi', '0121', '01223585236', '01223585334', '0125698789', '02', '020603', '0207', '02070836089', '02072069400', '02073162414', '02085076972', '020903', '021', '050703', '0578', '06', '060505', '061104', '07008009200', '07046744435', '07090201529', '07090298926', '07099833605', '071104', '07123456789', '0721072', '07732584351', '07734396839', '07742676969', '07753741225', '0776xxxxxxx', '07786200117', '077xxx', '078', '07801543489', '07808', '07808247860', '07808726822', '07815296484', '07821230901', '0784987', '0789xxxxxxx', '0794674629107880867867', '0796xxxxxx', '07973788240', '07xxxxxxxxx', '0800', '08000407165', '08000776320', '08000839402', '08000930705', '08000938767', '08001950382', '08002888812', '08002986030', '08002986906', '08002988890', '08006344447', '0808', '08081263000', '08081560665', '0825', '0844', '08448350055', '08448714184', '0845', '08450542832', '08452810071', '08452810073', '08452810075over18', '0870', '08700621170150p', '08701213186', '08701237397', '08701417012', '08701417012150p', '0870141701216', '087016248', '08701752560', '087018728737', '0870241182716', '08702490080', '08702840625', '08702840625comuk', '08704439680', '08704439680tsc', '08706091795', '0870737910216yr', '08707500020', '08707509020', '0870753331018', '08707808226', '08708034412', '08708800282', '08709222922', '08709501522', '0870k', '087104711148', '08712101358', '08712103738', '0871212025016', '08712300220', '087123002209am7pm', '08712317606', '08712400200', '08712400603', '08712402050', '08712402578', '08712402779', '08712402902', '08712402972', '08712404000', '08712405020', '08712405022', '08712460324', '08712460324nat', '08712466669', '0871277810710pmin', '0871277810810', '0871277810910pmin', '087143423992stop', '087147123779am7pm', '08714712379', '08714712388', '08714712394', '08714712412', '08714714011', '08714719523', '08715203028', '08715203649', '08715203652', '08715203656', '08715203677', '08715203685', '08715203694', '08715205273', '08715500022', '08715705022', '08717111821', '08717168528', '08717205546', '08717507382', '08717507711', '08717509990', '08717890890', '08717895698', '08717898035', '08718711108', '08718720201', '08718723815', '08718725756', '08718726270', '08718726270150gbpmtmsg18', '08718726970', '08718726971', '08718726978', '087187272008', '08718727868', '08718727870', '08718729755', '08718729758', '08718730555', '08718730666', '08718738001', '08718738002', '08718738034', '08719180219', '08719180248', '08719181259', '08719181503', '08719181513', '08719839835', '08719899217', '08719899229', '08719899230', '09041940223', '09050000301', '09050000332', '09050000460', '09050000555', '09050000878', '09050000928', '09050001295', '09050001808', '09050002311', '09050003091', '09050005321', '09050090044', '09050280520', '09053750005', '09056242159', '09057039994', '09058091854', '09058091870', '09058094454', '09058094455', '09058094507', '09058094565', '09058094583', '09058094594', '09058094597', '09058094599', '09058095107', '09058095201', '09058097189', '09058097218', '09058098002', '09058099801', '09061104276', '09061104283', '09061209465', '09061213237', '09061221061', '09061221066', '09061701444', '09061701461', '09061701851', '09061701939', '09061702893', '09061743386', '09061743806', '09061743810', '09061743811', '09061744553', '09061749602', '09061790121', '09061790125', '09061790126', '09063440451', '09063442151', '09063458130', '0906346330', '09064011000', '09064012103', '09064012160', '09064015307', '09064017295', '09064017305', '09064018838', '09064019014', '09064019788', '09065069120', '09065069154', '09065171142stopsms08', '09065171142stopsms08718727870150ppm', '09065174042', '09065394514', '09065394973', '09065989180', '09065989182', '09066350750', '09066358152', '09066358361', '09066361921', '09066362206', '09066362220', '09066362231', '09066364311', '09066364349', '09066364589', '09066368327', '09066368470', '09066368753', '09066380611', '09066382422', '09066612661', '09066649731from', '09066660100', '09071512432', '09071512433', '09071517866', '09077818151', '09090204448', '09090900040', '09094100151', '09094646631', '09094646899', '09095350301', '09096102316', '09099725823', '09099726395', '09099726429', '09099726481', '09099726553', '09111030116', '09111032124', '09701213186', '0anetwork', '1', '10', '100', '1000', '10000', '100000', '1000call', '100603', '100psm', '1010', '1013', '101mega', '1030', '10803', '10am', '10am7pm', '10am9pm', '10k', '10p', '10pmin', '10ppm', '10th', '11', '1120', '113', '1131', '11414', '1146', '1148', '116', '1172', '118pmsg', '11mth', '12', '120', '12000pe', '1205', '121', '1225', '123', '1230', '125', '1250', '125gift', '128', '12hour', '12hr', '12mth', '12price', '13', '130', '131004', '1327', '13404', '139', '140', '1405', '140ppm', '145', '1450', '146tf150p', '14thmarch', '150', '1500', '150ea', '150morefrmmob', '150msg', '150mtmsgrcvd18', '150p', '150pday', '150perweeksub', '150perwksub', '150pm', '150pmeg', '150pmin', '150pmmorefrommobile2bremovedmobypobox734ls27yf', '150pmsg', '150pmsgrcvd', '150pmsgrcvdhgsuite3422landsroww1j6hl', '150pmt', '150pmtmsg', '150pmtmsgrcvd18', '150ppermesssubscript', '150ppm', '150ppmpobox10183bhamb64x', '150ppmsg', '150prcvd', '150psm', '150ptext', '150ptone', '150pw', '150pwk', '150rcvd', '150week', '150wk', '151', '1526', '153', '15541', '15pmin', '16', '1680', '169', '16onli', '177', '18', '180', '181104', '1843', '186', '18onli', '18ptxt', '18yr', '195', '1956669', '1U', '1appledayno', '1childish', '1cup', '1da', '1er', '1hanuman', '1hi', '1hr', '1im', '1lemondayno', '1mcflyall', '1million', '1minmobsmor', '1minmobsmorelkpobox177hp51fl', '1minmoremobsemspobox45po139wa', '1month', '1pm', '1s', '1st', '1st4term', '1stchoicecouk', '1stone', '1tulsi', '1u', '1unbreak', '1winaweek', '1winawk', '1x150pwk', '1yf', '2', '20', '200', '2000', '20000', '2003', '2004', '2005', '2006', '2007', '2025050', '20f', '20m12aq', '20p', '20pmin', '21', '211104', '215', '21870000hi', '21m', '21st', '22', '220cm2', '23', '2309', '230ish', '24', '241', '241004', '247mp', '24hr', '24m', '24th', '25', '250', '250k', '255', '25f', '25p', '260305', '261004', '261104', '2667', '26th', '2703', '27603', '28', '2814032', '285', '28day', '28th', '28thfebtc', '290305', '29100', '29m', '2B', '2C', '2I', '2U', '2bajarangabali', '2bold', '2channel', '2day', '2daylov', '2docdpleas', '2end', '2exit', '2ez', '2getha', '2geva', '2go', '2godid', '2gthr', '2hook', '2hr', '2im', '2kbsubject', '2marrow', '2moro', '2morow', '2morro', '2morrow', '2morrowxxxx', '2mro', '2mrw', '2mwen', '2naughti', '2nd', '2nhite', '2night', '2nite', '2nitetel', '2optout', '2optoutd3wv', '2p', '2polic', '2px', '2rcv', '2stop', '2stoptx', '2stoptxt', '2u', '2u2', '2untam', '2watershd', '2waxsto', '2when', '2wk', '2wt', '2wu', '2year', '2yr', '3', '30', '300', '3000', '300603', '300603tcsbcm4235wc1n3xxcallcost150ppmmobilesvari', '300p', '3030', '30apr', '30pptxt', '30th', '31', '3100', '310303', '311004', '31pmsg150p', '32000', '3230', '32323', '326', '32f', '330', '3350', '3365', '350', '3510i', '35p', '3650', '36504', '3680', '3680offer', '373', '3750', '375max', '38', '391784', '399', '3G', '3U', '3aj', '3cover', '3d', '3day', '3db', '3g', '3gbp', '3hr', '3lion', '3lp', '3maruti', '3mile', '3min', '3mobil', '3optic', '3pound', '3qxj9', '3rd', '3sentiment', '3ss', '3u', '3unkempt', '3uz', '3wife', '3wk', '3x', '3xx', '4', '40', '400', '400minscal', '402', '4041', '40411', '40533', '40gb', '40mph', '415', '41685', '41782', '420', '42049', '4217', '42478', '42810', '430', '434', '44', '4403ldnw1a7rw18', '447797706009', '447801259231', '447per', '448712404000pleas', '449050000301', '449071512431', '449month', '45', '450', '450p', '450ppw', '450pw', '45239', '46', '47', '4712', '4742', '48', '4882', '48922', '49557', '4U', '4a', '4brekki', '4cook', '4d', '4eva', '4few', '4fil', '4get', '4give', '4got', '4goten', '4info', '4jx', '4lux', '4mi', '4mth', '4o', '4pavanaputra', '4press', '4rowdi', '4some1', '4tctxt', '4th', '4the', '4thnovbehind', '4txt120p', '4txtú120', '4u', '4ui', '4utxt', '4w', '4ward', '4wrd', '4year', '5', '50', '500', '5000', '500000', '505060', '50award', '50p', '515', '515pm', '5226', '5249', '526', '528', '530', '532', '54', '542', '545', '5903', '5I', '5K', '5digit', '5free', '5ful', '5garden', '5gentli', '5ish', '5min', '5ml', '5month', '5p', '5pm', '5sankatmochan', '5terror', '5th', '5wb', '5we', '5wkg', '5wq', '5year', '6', '600', '6031', '60400thousadi', '60p', '60pmin', '61200', '61610', '62220cncl', '6230', '62468', '62735', '630', '63mile', '645', '645pm', '650', '6669', '67441233', '68866', '69101', '69200', '69669', '69696', '69698', '69855', '6986618', '69876', '69888', '69888nyt', '69911', '69969', '69988', '6cruel', '6day', '6hl', '6housemaid', '6hr', '6ish', '6miss', '6month', '6pm', '6ramaduth', '6romant', '6th', '6time', '6wu', '6zf', '7', '700', '71', '725', '7250', '7250i', '730', '730ish', '730pm', '731', '74355', '750', '75000', '7548', '7634', '7684', '7732584351', '78', '786', '7876150ppm', '78pmin', '79', '7am', '7cfca1a', '7children', '7ish', '7mahav', '7oz', '7pm', '7romant', '7shi', '7th', '7w', '7z', '8', '80', '800', '8000930705', '80062', '8007', '80082', '80086', '80122300pwk', '80155', '80160', '80182', '8027', '80488', '80488biz', '80608', '8077', '80878', '81010', '81151', '81303', '81618', '816183', '82242', '82277', '82277unsub', '82324', '82468', '830', '83021', '83039', '83049', '83110', '83118', '83222', '83332pleas', '83338', '83355', '83370', '83383', '83435', '83600', '83738', '84', '84025', '84122', '84128', '84128custcar', '84199', '84484', '85', '850', '85023', '85069', '85222', '85233', '8552', '85555', '86021', '861', '863', '864233', '86688', '86888', '87021', '87066', '87070', '87077', '87121', '87131', '8714714', '87239', '87575', '8800', '88039', '88039skilgmetscs087147403231winawkage16', '88066', '88088', '88222', '8830', '88600', '88800', '8883', '88877', '88877free', '88888', '89034', '89070', '89080', '89105', '89123', '89545', '89555', '89693', '89938', '8am', '8attract', '8ball', '8hr', '8lb', '8lovabl', '8neighbour', '8o', '8pm', '8th', '8wp', '9', '900', '9061100010', '9153', '924', '92h', '930', '945', '946', '95pax', '96', '97n7qp', '98321561', '9996', '9ae', '9am', '9am11pm', '9decent', '9funni', '9ja', '9pm', '9t', '9th', '9yt', 'A', 'AD', 'AG', 'AH', 'AL', 'AM', 'AN', 'AS', 'AT', 'AV', 'Ab', 'Ah', 'Al', 'Am', 'An', 'As', 'At', 'Ay', 'B', 'B4', 'BE', 'BK', 'BT', 'BY', 'Bc', 'Be', 'Bt', 'Bx', 'By', 'C', 'CC', 'CD', 'CL', 'CM', 'CU', 'Co', 'Cs', 'D', 'DA', 'DD', 'DE', 'DO', 'Da', 'De', 'Do', 'Dr', 'E', 'ER', 'EY', 'Ee', 'Eh', 'Em', 'En', 'Er', 'Ew', 'F', 'FA', 'Fr', 'G', 'G2', 'GB', 'GO', 'Gd', 'Ge', 'Gn', 'Go', 'H', 'HI', 'HL', 'HM', 'HU', 'Ha', 'He', 'Hi', 'Hm', 'Ho', 'I', 'ID', 'IF', 'IL', 'IM', 'IN', 'IQ', 'IS', 'IT', 'Ic', 'Id', 'If', 'Im', 'In', 'Is', 'It', 'J', 'JD', 'K', 'KR', 'Ki', 'Ku', 'L', 'LE', 'Lk', 'M', 'M6', 'ME', 'MF', 'MO', 'MR', 'MY', 'Ma', 'Me', 'Mm', 'Mr', 'My', 'N', 'NO', 'No', 'Nt', 'Nw', 'O', 'O2', 'OF', 'OH', 'OK', 'ON', 'OR', 'Of', 'Oh', 'Oi', 'Ok', 'On', 'Or', 'Oz', 'P', 'PA', 'PC', 'PO', 'PS', 'Pa', 'Pg', 'Pl', 'Po', 'Q', 'R', 'RV', 'Re', 'Rs', 'S', 'S8', 'SD', 'SF', 'SI', 'SN', 'SO', 'SP', 'ST', 'Si', 'So', 'St', 'T', 'TA', 'TC', 'TH', 'TO', 'TV', 'TX', 'Ta', 'Tb', 'To', 'Ts', 'U', 'U4', 'UK', 'UP', 'UR', 'US', 'UU', 'Uh', 'Up', 'Ur', 'Us', 'V', 'VE', 'VU', 'W4', 'WE', 'WK', 'Wa', 'We', 'Wk', 'Wn', 'X', 'X2', 'XX', 'Xx', 'Xy', 'Y', 'YA', 'YM', 'YO', 'Ya', 'Yo', 'Z', 'a21', 'a30', 'aa', 'aah', 'aaniy', 'aaooooright', 'aathilov', 'aathiwher', 'abbey', 'abdomen', 'abeg', 'abelu', 'aberdeen', 'abi', 'abil', 'abiola', 'abj', 'abl', 'abnorm', 'about', 'abouta', 'abroad', 'absenc', 'absolut', 'abstract', 'abt', 'abta', 'aburo', 'abus', 'ac', 'academ', 'acc', 'accent', 'accentur', 'accept', 'access', 'accid', 'accident', 'accommod', 'accommodationvouch', 'accomod', 'accordin', 'accordingli', 'accordinglyor', 'account', 'accumul', 'ach', 'achanammarakheshqatar', 'achiev', 'acid', 'acknowledg', 'acl03530150pm', 'acnt', 'acoentry41', 'across', 'acsmsreward', 'act', 'actin', 'action', 'activ', 'activ8', 'actor', 'actual', 'acwicmb3cktz8r74', 'ad', 'adam', 'add', 'addamsfa', 'addi', 'addict', 'address', 'addressul', 'adewal', 'adi', 'adjust', 'admin', 'administr', 'admir', 'admiss', 'admit', 'admiti', 'ador', 'adp', 'adress', 'adrian', 'adrink', 'adsens', 'adult', 'advanc', 'adventur', 'advic', 'advis', 'advisor', 'aeronaut', 'aeroplan', 'afew', 'affair', 'affect', 'affection', 'affectionsamp', 'affidavit', 'afford', 'afghanistan', 'afraid', 'africa', 'african', 'aft', 'after', 'afternon', 'afternoon', 'afterward', 'aftr', 'again', 'againcal', 'againlov', 'against', 'agalla', 'age', 'age16', 'age16150ppermesssubscript', 'age23', 'agenc', 'agent', 'agesr', 'agidhan', 'ago', 'agocusoon', 'agre', 'agreen', 'ah', 'aha', 'ahead', 'ahge', 'ahhh', 'ahhhhjust', 'ahmad', 'ahnow', 'ahold', 'ahsen', 'ahth', 'ahwhat', 'aid', 'aig', 'aight', 'aint', 'air', 'air1', 'airport', 'airtel', 'aiya', 'aiyah', 'aiyar', 'aiyo', 'ajith', 'ak', 'aka', 'akonlon', 'al', 'alaikkumprid', 'alaipayuth', 'albi', 'album', 'albumquit', 'alcohol', 'aldrin', 'alert', 'alertfrom', 'alett', 'alex', 'alfi', 'algarv', 'algebra', 'algorithm', 'ali', 'alian', 'alibi', 'aliv', 'alivebett', 'all', 'allah', 'allahmeet', 'allahrakhesh', 'allalo', 'allday', 'allo', 'allow', 'almost', 'alon', 'along', 'alot', 'alreadi', 'alreadysabarish', 'alright', 'alrightokay', 'alrit', 'alritehav', 'also', 'alsoor', 'alter', 'alternativehop', 'although', 'alwa', 'alway', 'alwi', 'am', 'amanda', 'amaz', 'ambiti', 'ambrithmaduraimet', 'american', 'ami', 'amigo', 'amk', 'ammaelif', 'ammo', 'amnow', 'among', 'amongst', 'amor', 'amount', 'amp', 'amplikat', 'amrca', 'amrita', 'amt', 'amus', 'amx', 'an', 'ana', 'anal', 'analysi', 'anand', 'and', 'anderson', 'andor', 'andr', 'andrewsboy', 'andro', 'angel', 'angri', 'ani', 'anim', 'anji', 'anjola', 'anna', 'anni', 'anniversari', 'annonc', 'announc', 'annoy', 'annoyin', 'anonym', 'anot', 'anoth', 'ansr', 'answer', 'answerin', 'answr', 'antelop', 'anthoni', 'anti', 'antibiot', 'anybodi', 'anyhow', 'anymor', 'anyon', 'anyplac', 'anyth', 'anythi', 'anythin', 'anythingtomorrow', 'anytim', 'anyway', 'anywher', 'aom', 'apart', 'ape', 'apeshit', 'aphex', 'apnt', 'apo', 'apolog', 'apologet', 'apologis', 'app', 'appar', 'appeal', 'appear', 'appendix', 'appi', 'applebe', 'applespairsal', 'appli', 'applic', 'apply2', 'appoint', 'appreci', 'approach', 'appropri', 'approv', 'approx', 'appt', 'april', 'aproach', 'apt', 'aptitud', 'aquariu', 'ar', 'arab', 'arabian', 'arcad', 'archiv', 'ard', 'ardé', 'are', 'area', 'arent', 'arestaur', 'aretak', 'argentina', 'argh', 'argu', 'argument', 'ari', 'aris', 'arithmet', 'arm', 'armand', 'armenia', 'arng', 'arngd', 'arnt', 'around', 'aroundn', 'arpraveesh', 'arr', 'arrang', 'arrest', 'arriv', 'arrow', 'arsen', 'art', 'arti', 'artist', 'arul', 'arun', 'asa', 'asap', 'asapok', 'asda', 'ash', 'ashley', 'ashwini', 'asia', 'asian', 'ask', 'askd', 'askin', 'aslamalaikkuminsha', 'asleep', 'aspect', 'ass', 'assess', 'asshol', 'assist', 'associ', 'assum', 'asther', 'asthma', 'astn', 'astoundingli', 'astrolog', 'astronom', 'asu', 'asusual1', 'ate', 'athlet', 'athom', 'atlanta', 'atlast', 'atleast', 'atm', 'atroci', 'attach', 'attack', 'attempt', 'atten', 'attend', 'attent', 'attitud', 'attract', 'attractioni', 'attribut', 'atyour', 'auction', 'auctionpunj', 'audiit', 'audit', 'audrey', 'audri', 'august', 'aunt', 'aunti', 'aust', 'australia', 'authoris', 'auto', 'autocorrect', 'av', 'ava', 'avail', 'availa', 'availablei', 'availablethey', 'avalarr', 'avatar', 'avbl', 'ave', 'aveng', 'avent', 'avenu', 'avin', 'avo', 'avoid', 'await', 'awak', 'award', 'away', 'awesom', 'awkward', 'aww', 'awww', 'ax', 'axi', 'ayn', 'ayo', 'b', 'b4', 'b4190604', 'b4280703', 'b4u', 'ba', 'ba128nnfwfly150ppm', 'baaaaaaaab', 'baaaaab', 'babe', 'babeprobpop', 'babesozi', 'babi', 'babygoodby', 'babyhop', 'babyjontet', 'babysit', 'bac', 'back', 'backa', 'backdoor', 'backward', 'bad', 'badass', 'badli', 'badrith', 'bag', 'bagi', 'bahama', 'baig', 'bailiff', 'bak', 'bakra', 'bakrid', 'balanc', 'ball', 'baller', 'balloon', 'bam', 'bambl', 'ban', 'band', 'bandag', 'bang', 'bangb', 'bangbab', 'bani', 'bank', 'banneduk', 'banter', 'bao', 'bar', 'barbi', 'barcelona', 'bare', 'bari', 'barkley', 'barm', 'barolla', 'barrel', 'barri', 'base', 'bash', 'basic', 'basket', 'basketbal', 'basqihav', 'bat', 'batch', 'batchlor', 'bath', 'bathroom', 'batsman', 'batt', 'batteri', 'battl', 'bawl', 'bay', 'bb', 'bbc', 'bbdelux', 'bbdpooja', 'bbdtht', 'bblue', 'bbq', 'bc', 'bcaz', 'bck', 'bcm', 'bcm1896wc1n3xx', 'bcm4284', 'bcmsfwc1n3xx', 'bcoz', 'bcozi', 'bcum', 'bcz', 'bday', 'be', 'beach', 'bead', 'bear', 'beat', 'beauti', 'beautifulmay', 'bec', 'becau', 'becaus', 'becausethey', 'becom', 'becoz', 'becz', 'bed', 'bedbut', 'bedreal', 'bedrm', 'bedrm900', 'bedroom', 'bedroomlov', 'beeen', 'beehoon', 'been', 'beendrop', 'beer', 'beerag', 'beerr', 'befor', 'beforehand', 'beforew', 'beg', 'beggar', 'begin', 'begun', 'behalf', 'behav', 'behind', 'bein', 'believ', 'beliv', 'bell', 'bellearli', 'belli', 'belliger', 'belong', 'belov', 'belovd', 'belt', 'ben', 'bend', 'beneath', 'beneficiari', 'benefit', 'benni', 'bergkamp', 'besid', 'best', 'best1', 'bestcongrat', 'bestrpli', 'bet', 'beta', 'beth', 'betta', 'better', 'bettersn', 'beverag', 'bevieswaz', 'bewar', 'beyond', 'bf', 'bff', 'bfore', 'bhaskar', 'bhayandar', 'bian', 'biatch', 'bid', 'big', 'bigger', 'biggest', 'bike', 'bill', 'billi', 'billion', 'bilo', 'bimbo', 'bin', 'biola', 'bird', 'birla', 'biro', 'birth', 'birthdat', 'birthday', 'bishan', 'bit', 'bitch', 'bite', 'bk', 'black', 'blackand', 'blackberri', 'blackim', 'blacko', 'blah', 'blake', 'blame', 'blank', 'blanket', 'blastin', 'bleak', 'bleh', 'bless', 'blessget', 'blimey', 'blind', 'block', 'blog', 'bloke', 'blond', 'bloo', 'blood', 'bloodblood', 'bloodi', 'bloodsend', 'bloomberg', 'bloombergcom', 'blow', 'blown', 'blu', 'blue', 'bluetooth', 'bluetoothhdset', 'blueu', 'bluff', 'blur', 'bluray', 'bmw', 'board', 'boat', 'boatin', 'bob', 'bodi', 'boggi', 'bognor', 'bold', 'bold2', 'bollox', 'boltblu', 'bomb', 'bone', 'bong', 'bonu', 'boo', 'boob', 'book', 'bookedth', 'bookmark', 'bookshelf', 'boooo', 'boost', 'booti', 'bootydeli', 'borderlin', 'bore', 'borin', 'born', 'bornpleas', 'borrow', 'boss', 'boston', 'bot', 'both', 'bother', 'bottl', 'bottom', 'bought', 'boundari', 'bout', 'boutxx', 'bowa', 'bowl', 'box', 'box1146', 'box139', 'box177', 'box245c2150pm', 'box326', 'box334', 'box334sk38ch', 'box385', 'box39822', 'box403', 'box420', 'box42wr29c', 'box434sk38wp150ppm18', 'box61m60', 'box95qu', 'box97n7qp', 'boy', 'boyf', 'boyfriend', 'boyi', 'boytoy', 'bpo', 'bra', 'brah', 'brain', 'braindanc', 'braini', 'brainless', 'brand', 'brandi', 'brat', 'brave', 'bray', 'brb', 'brdget', 'bread', 'breadstick', 'break', 'breaker', 'breakfast', 'breakin', 'breath', 'breathe1', 'breather', 'breez', 'breezi', 'bribe', 'bridg', 'bridgwat', 'brief', 'bright', 'brighten', 'brilliant', 'brilliant1thingi', 'brilliantli', 'brin', 'bring', 'brisk', 'brison', 'bristol', 'british', 'britney', 'bro', 'broad', 'broadband', 'broke', 'broken', 'brolli', 'broth', 'brotha', 'brother', 'brought', 'browni', 'brows', 'browser', 'browsin', 'bruce', 'brum', 'bruv', 'bslvyl', 'bsn', 'bsnl', 'bstfrnd', 'bt', 'bthere', 'bthmm', 'btnation', 'btnationalr', 'btooth', 'btw', 'btwn', 'bu', 'buck', 'bud', 'buddi', 'budget', 'buen', 'buff', 'buffet', 'buffi', 'bugi', 'build', 'built', 'bulb', 'bull', 'bullshit', 'bun', 'bunch', 'bundl', 'bunker', 'burden', 'burger', 'burgundi', 'burial', 'burn', 'burnt', 'burrito', 'bus822656166382', 'buse', 'busetop', 'busi', 'busti', 'busyi', 'but', 'butt', 'butther', 'button', 'buy', 'buyer', 'buz', 'buzi', 'buzz', 'buzzzz', 'bw', 'bx420', 'bx420ip45w', 'bx526', 'byatch', 'bye', 'c', 'c52', 'cab', 'cabin', 'cabl', 'cafe', 'cage', 'cake', 'caken', 'cal', 'calcul', 'cali', 'calicut', 'california', 'call', 'call09050000327', 'call2optout4qf2', 'call2optout674', 'call2optoutf4q', 'call2optouthf8', 'call2optoutj', 'call2optoutj5q', 'call2optoutlf56', 'call2optoutn9dx', 'call2optoutyhl', 'callback', 'callcost', 'callcoz', 'calld', 'calldrov', 'caller', 'callertun', 'callfreefon', 'callin', 'callingforgot', 'callon', 'calls150ppm', 'callsmessagesmiss', 'callurg', 'calm', 'cam', 'camcord', 'came', 'camera', 'cameravideo', 'camp', 'campu', 'camri', 'can', 'canada', 'canal', 'canari', 'cancel', 'cancer', 'candont', 'canlov', 'cannam', 'cannot', 'cannt', 'cant', 'cantdo', 'canteen', 'cap', 'capac', 'capit', 'cappuccino', 'captain', 'car', 'card', 'cardiff', 'cardin', 'care', 'careabout', 'career', 'careinsha', 'careless', 'carent', 'careswt', 'careumma', 'carewhoev', 'carli', 'carlin', 'carlo', 'carlosl', 'carolin', 'carolina', 'carpark', 'carri', 'carryin', 'carso', 'carton', 'cartoon', 'case', 'cash', 'cashbal', 'cashbincouk', 'cashin', 'cashto', 'cast', 'castor', 'casualti', 'cat', 'catch', 'categori', 'caught', 'caus', 'cave', 'caveboy', 'cbe', 'cc100pmin', 'ccna', 'cd', 'cdgt', 'cedar', 'ceil', 'celeb', 'celeb4', 'celebr', 'cell', 'censu', 'center', 'centr', 'centuri', 'cer', 'cereal', 'ceri', 'certainli', 'certif', 'cha', 'chachi', 'chad', 'chain', 'challeng', 'champ', 'champlaxig', 'champney', 'chanc', 'chang', 'channel', 'chap', 'chapel', 'chapter', 'charact', 'charg', 'charged150pmsg2', 'chariti', 'charl', 'charli', 'charm', 'chart', 'chase', 'chastiti', 'chat', 'chat80155', 'chatim', 'chatlin', 'chatter', 'cheap', 'cheaper', 'cheat', 'chechi', 'check', 'checkbox', 'checkin', 'checkmat', 'checkup', 'cheek', 'cheer', 'cheeri', 'chees', 'cheesi', 'cheeto', 'chef', 'chennai', 'chennaibecaus', 'chennaii', 'chequ', 'cherish', 'cherthalain', 'chess', 'chest', 'chex', 'cheyyamoand', 'chez', 'chg', 'chic', 'chick', 'chicken', 'chief', 'chik', 'chikku', 'chikkuali', 'chikkub', 'chikkudb', 'chikkugo', 'chikkuil', 'chikkuk', 'chikkusimpl', 'chikkuwat', 'child', 'childish', 'childporn', 'children', 'chile', 'chill', 'chillaxin', 'chillin', 'china', 'chinatown', 'chinchilla', 'chines', 'chinki', 'chiong', 'chip', 'chitchat', 'chk', 'chloe', 'chocol', 'choic', 'choos', 'chop', 'chord', 'chore', 'chosen', 'chrgd50p', 'christ', 'christian', 'christma', 'christmasmerri', 'christmassi', 'chuck', 'chuckin', 'church', 'ciao', 'cin', 'cine', 'cinema', 'citi', 'citizen', 'citylink', 'cla', 'claim', 'claimcod', 'clair', 'clarif', 'clarifi', 'clash', 'class', 'classic', 'classmat', 'claypot', 'cld', 'clean', 'clear', 'clearer', 'clearli', 'clever', 'click', 'cliff', 'clip', 'clock', 'clos1', 'close', 'closebi', 'closedinclud', 'closer', 'closingdate040902', 'cloth', 'cloud', 'clover', 'club', 'club4', 'club4mobilescom', 'clue', 'cm', 'cme', 'cmon', 'cn', 'cnl', 'cnn', 'co', 'coach', 'coast', 'coat', 'coax', 'cocacola', 'coccoon', 'cochin', 'cock', 'cocksuck', 'coco', 'code', 'code4xx26', 'coffe', 'coher', 'coimbator', 'coin', 'coincid', 'colani', 'cold', 'coldheard', 'colin', 'collag', 'collaps', 'colleagu', 'collect', 'colleg', 'collegexx', 'color', 'colour', 'colourredtextcolourtxtstar', 'com', 'comb', 'combin', 'come', 'comedi', 'comedyc', 'comei', 'cometil', 'comfey', 'comfort', 'comin', 'comingdown', 'comingtmorow', 'command', 'comment', 'commerci', 'commit', 'common', 'commun', 'comp', 'compani', 'companion', 'compar', 'compass', 'compens', 'competit', 'complac', 'complain', 'complaint', 'complementari', 'complet', 'complex', 'compliment', 'complimentari', 'compofstuff', 'comprehens', 'compromis', 'compulsori', 'comput', 'computerless', 'comuk220cm2', 'con', 'conact', 'concentr', 'concern', 'concert', 'conclus', 'condit', 'conditionand', 'conduct', 'conect', 'confer', 'confid', 'configur', 'confirm', 'confirmd', 'confirmdeni', 'conform', 'confus', 'congrat', 'congratul', 'connect', 'consensu', 'consent', 'conserv', 'consid', 'consist', 'consol', 'constant', 'constantli', 'contact', 'contain', 'content', 'contin', 'continu', 'contract', 'contribut', 'control', 'conveni', 'convers', 'convert', 'convey', 'convinc', 'convincingjust', 'cook', 'cooki', 'cool', 'coolmob', 'coop', 'cooper', 'cop', 'cope', 'copi', 'corect', 'cornwal', 'corpor', 'corrct', 'correct', 'correctionor', 'correctli', 'corrupt', 'corvett', 'cosign', 'cost', 'costa', 'costum', 'couch', 'cougarpen', 'cough', 'could', 'coulda', 'couldnt', 'count', 'countin', 'countinlot', 'countri', 'coupl', 'coupla', 'courag', 'cours', 'court', 'courtroom', 'cousin', 'cover', 'coveragd', 'coz', 'cozi', 'cozsomtim', 'cp', 'cr', 'cr01327bt', 'cr9', 'crab', 'crack', 'craigslist', 'cram', 'cramp', 'crap', 'crash', 'crave', 'crazi', 'craziest', 'crazyin', 'cream', 'creat', 'creativ', 'cred', 'credit', 'creep', 'creepi', 'cresubi', 'cri', 'cribb', 'cricket', 'crickit', 'crisi', 'crisisspk', 'cro1327', 'crore', 'cross', 'crowd', 'croydon', 'crucial', 'crucifi', 'cruis', 'cruisin', 'crush', 'cs', 'csh11', 'cst', 'cstore', 'ctagg', 'ctargg', 'cthen', 'ctla', 'cttargg', 'ctter', 'cttergg', 'cuck', 'cud', 'cuddl', 'cudnt', 'culdnt', 'cultur', 'cum', 'cumin', 'cup', 'cupboard', 'cuppa', 'curfew', 'curiou', 'current', 'curri', 'curtsey', 'cust', 'custcar', 'custcare08718720201', 'custom', 'customercar', 'customersqueriesnetvisionukcom', 'cut', 'cute', 'cutefrnd', 'cutest', 'cuti', 'cutter', 'cuz', 'cw25wx', 'cya', 'cyclist', 'cyst', 'da', 'daal', 'daalway', 'dabbl', 'dabook', 'dad', 'daddi', 'dado', 'dagood', 'dahe', 'dahow', 'dai', 'daili', 'dajst', 'dammit', 'damn', 'dan', 'danalla', 'danc', 'dancc', 'dancin', 'dane', 'dang', 'danger', 'dao', 'dapleas', 'dare', 'dark', 'darker', 'darkest', 'darl', 'darlin', 'darlinim', 'darren', 'dartboard', 'dasara', 'dat', 'data', 'date', 'datebox1282essexcm61xn', 'datingi', 'datoday', 'datz', 'daurgent', 'dave', 'dawhat', 'dawher', 'dawn', 'day', 'day2', 'day2find', 'dayexcept', 'dayha', 'daysh', 'daysso', 'dayswil', 'daysèn', 'daytim', 'dayu', 'daywith', 'de', 'dead', 'deadwel', 'deal', 'dealer', 'dealfarm', 'deam', 'dear', 'dear1', 'dearer', 'deari', 'dearli', 'dearlov', 'dearm', 'dearrakhesh', 'dearregret', 'dearshal', 'dearslp', 'deartak', 'death', 'debat', 'dec', 'decad', 'decemb', 'decid', 'decim', 'decis', 'deck', 'declar', 'decor', 'dedic', 'deduct', 'deep', 'deepak', 'deepest', 'deer', 'deeraj', 'def', 'defeat', 'defer', 'definit', 'definitli', 'defo', 'degre', 'dehydr', 'del', 'delay', 'delet', 'delhi', 'delici', 'deliv', 'deliveredtomorrow', 'deliveri', 'deltomorrow', 'delux', 'dem', 'demand', 'den', 'dena', 'dengra', 'deni', 'dent', 'dental', 'dentist', 'depart', 'depend', 'deposit', 'depress', 'dept', 'der', 'derek', 'derp', 'describ', 'descript', 'desert', 'deserv', 'design', 'desir', 'desk', 'despar', 'desper', 'despit', 'dessert', 'destin', 'destini', 'detail', 'detailsi', 'determin', 'detroit', 'deu', 'develop', 'devic', 'devil', 'devour', 'dey', 'deyhop', 'deyi', 'dha', 'dhina', 'dhoni', 'dhort', 'di', 'dial', 'diall', 'dialogu', 'diamond', 'diaper', 'dice', 'dick', 'dict', 'dictionari', 'did', 'diddi', 'didn', 'didnt', 'didntgiv', 'didt', 'die', 'diesel', 'diet', 'diff', 'differ', 'differb', 'difficult', 'difficulti', 'dificult', 'digi', 'digit', 'digniti', 'dileepthank', 'dime', 'dimens', 'din', 'dine', 'dinero', 'ding', 'dinner', 'dinnermsg', 'dino', 'dint', 'dip', 'dippeditinadew', 'direct', 'directli', 'director', 'dirt', 'dirti', 'dirtiest', 'disagre', 'disappear', 'disappoint', 'disast', 'disastr', 'disc', 'disclos', 'disconnect', 'discount', 'discreet', 'discuss', 'diseas', 'diskyou', 'dislik', 'dismay', 'dismissi', 'display', 'distanc', 'distract', 'disturb', 'disturbancemight', 'ditto', 'divert', 'divis', 'divorc', 'diwali', 'dizzamn', 'dizze', 'dl', 'dled', 'dlf', 'dload', 'dnt', 'do', 'dob', 'dobbi', 'doc', 'dock', 'doctor', 'document', 'dodda', 'dodgey', 'doe', 'doesdiscountshitinnit', 'doesnt', 'dog', 'dogbreath', 'dogg', 'doggi', 'doggin', 'dogwood', 'doin', 'doinat', 'doinghow', 'doingwhat', 'doinnearli', 'dointerest', 'doke', 'dokey', 'doll', 'dollar', 'dolld', 'dom', 'domain', 'don', 'donat', 'done', 'donew', 'donno', 'dont', 'dont4get2text', 'dontcha', 'dontignor', 'dontpleas', 'donyt', 'doom', 'door', 'dorm', 'dormitori', 'dorothykiefercom', 'dose', 'dosometh', 'dot', 'doubl', 'doublefaggot', 'doublemin', 'doubletxt', 'doubt', 'doug', 'dough', 'down', 'download', 'downon', 'downstem', 'dozen', 'dp', 'dr', 'dracula', 'drama', 'dramastorm', 'dramat', 'drastic', 'draw', 'drawpleas', 'dread', 'dream', 'dreamlov', 'dreamsmuah', 'dreamstak', 'dreamsu', 'dreamz', 'dress', 'dresser', 'dri', 'drink', 'drinkin', 'drinkpa', 'drive', 'driver', 'drivin', 'drizzl', 'drm', 'drmstake', 'drop', 'drove', 'drpd', 'drug', 'drugdeal', 'drum', 'drunk', 'drunkard', 'drunken', 'drvgsto', 'dryer', 'dsnt', 'dt', 'dual', 'dub', 'dubsack', 'duchess', 'duck', 'dude', 'dudett', 'due', 'duffer', 'dull', 'dumb', 'dump', 'dun', 'dungere', 'dunno', 'duo', 'durban', 'durham', 'dusk', 'dust', 'duvet', 'dvd', 'dvg', 'dwn', 'dysentri', 'e', 'e14', 'each', 'eachoth', 'ear', 'earli', 'earlier', 'earlierw', 'earliest', 'earn', 'earth', 'earthsofa', 'easi', 'easier', 'easiest', 'easili', 'east', 'eastend', 'easter', 'eat', 'eaten', 'eatin', 'ebay', 'ec2a', 'echo', 'eckankar', 'ecstaci', 'ecstasi', 'edg', 'edha', 'edison', 'edit', 'edrunk', 'educ', 'edukkukaye', 'edward', 'ee', 'eek', 'eeri', 'eerulli', 'effect', 'effici', 'efreefon', 'eg', 'eg23f', 'eg23g', 'egbon', 'egg', 'eggpotato', 'eggspert', 'ego', 'eh', 'eh74rr', 'eight', 'eighth', 'eightish', 'eir', 'either', 'el', 'ela', 'elabor', 'elain', 'elama', 'elaya', 'eldest', 'elect', 'electr', 'eleph', 'eleven', 'elliot', 'ello', 'els', 'elsewher', 'elvi', 'em', 'email', 'embarass', 'embarrass', 'embassi', 'emerg', 'emigr', 'emili', 'emot', 'employ', 'employe', 'empti', 'en', 'enam', 'enc', 'end', 'endless', 'endof', 'endow', 'enemi', 'energi', 'eng', 'engag', 'engalnd', 'engin', 'england', 'english', 'enjoy', 'enjoyin', 'enketa', 'enna', 'ennal', 'enough', 'enter', 'entertain', 'entey', 'entir', 'entitl', 'entrepreneur', 'entri', 'entrop', 'enufcredeit', 'enuff', 'envelop', 'envi', 'epi', 'epsilon', 'equal', 'ericson', 'ericsson', 'erm', 'erot', 'err', 'error', 'ertini', 'eruku', 'erupt', 'erutupalam', 'eryth', 'esaplanad', 'escal', 'escap', 'ese', 'eshxxxxxxxxxxx', 'especi', 'espel', 'esplanad', 'essay', 'essenti', 'establish', 'eta', 'etc', 'etern', 'ethnic', 'ethreat', 'ettan', 'euro', 'euro2004', 'eurodisinc', 'europ', 'evalu', 'evapor', 'eve', 'eveb', 'evei', 'even', 'event', 'eventu', 'ever', 'everi', 'every1', 'everybodi', 'everyboy', 'everyday', 'everyon', 'everyso', 'everyth', 'everythin', 'everytim', 'everywher', 'evey', 'evict', 'evil', 'evn', 'evng', 'evo', 'evon', 'evr', 'evrey', 'evri', 'evry1', 'evrydi', 'ex', 'exact', 'exactli', 'exam', 'excel', 'except', 'exchang', 'excit', 'excus', 'exe', 'execut', 'exercis', 'exet', 'exhaust', 'exhibit', 'exist', 'exmpel', 'exorc', 'exorcist', 'exp', 'expect', 'expens', 'experi', 'experiencehttpwwwvouch4mecometlpdiningasp', 'expert', 'expir', 'expiredso', 'expiri', 'explain', 'explicit', 'explicitli', 'explos', 'expos', 'express', 'ext', 'extermin', 'extra', 'extract', 'extrem', 'exwif', 'ey', 'eye', 'eyeddont', 'f', 'fab', 'faber', 'face', 'faceasssssholeee', 'facebook', 'facil', 'fact', 'factori', 'fade', 'faggi', 'faglord', 'fail', 'failur', 'faint', 'fair', 'faith', 'faitheven', 'fake', 'fakemi', 'fakey', 'fal', 'falconerf', 'fall', 'fallen', 'famamu', 'famili', 'familiar', 'familymay', 'famou', 'fan', 'fanci', 'fantasi', 'fantast', 'far', 'farm', 'farrel', 'fart', 'fassyol', 'fast', 'faster', 'fastest', 'fastpl', 'fat', 'fate', 'father', 'fathima', 'fatti', 'fault', 'faultal', 'faultf', 'fav', 'fave', 'favor', 'favorit', 'favour', 'favourit', 'fb', 'fear', 'featheri', 'featur', 'feb', 'febapril', 'februari', 'fedex', 'fee', 'feed', 'feel', 'feelin', 'feelingood', 'feelingwav', 'feet', 'fell', 'fellow', 'felt', 'femal', 'feng', 'festiv', 'fetch', 'fever', 'fffff', 'ffffffffff', 'ffffuuuuuuu', 'fgkslpo', 'fgkslpopw', 'fidalf', 'field', 'fieldof', 'fiendmak', 'fifa', 'fifteen', 'fifth', 'fifti', 'fight', 'fightng', 'figur', 'file', 'fill', 'film', 'filth', 'filthi', 'filthyguy', 'final', 'finalis', 'financ', 'financi', 'find', 'fine', 'fineabsolutli', 'fineinshah', 'finest', 'finewhen', 'finger', 'finish', 'finishd', 'fink', 'finn', 'fire', 'firefox', 'fireplac', 'firesar', 'firmwar', 'firsg', 'first', 'fish', 'fishhead', 'fishrman', 'fit', 'fite', 'five', 'fix', 'fixd', 'fixedlin', 'fizz', 'flag', 'flake', 'flaki', 'flame', 'flash', 'flat', 'flatter', 'flavour', 'flea', 'fletcher', 'flew', 'fli', 'flight', 'flim', 'flip', 'flippin', 'flirt', 'float', 'flood', 'floor', 'floppi', 'florida', 'flow', 'flower', 'fluid', 'flung', 'flurri', 'flute', 'flyim', 'flyng', 'fml', 'fmyou', 'fne', 'fo', 'fold', 'foley', 'folk', 'follow', 'followin', 'fond', 'fondli', 'fone', 'fonin', 'food', 'fool', 'foot', 'footbal', 'footblcrckt', 'footi', 'footprint', 'for', 'forc', 'foreg', 'foreign', 'forev', 'forevr', 'forfeit', 'forget', 'forgiv', 'forgiven', 'forgot', 'forgotten', 'forgt', 'form', 'formal', 'formallypl', 'format', 'formclark', 'formsdon', 'forth', 'fortun', 'forum', 'forward', 'found', 'foundurself', 'four', 'fourth', 'foward', 'fowler', 'fox', 'fp', 'fr', 'fraction', 'fran', 'frankgood', 'franki', 'franxx', 'franyxxxxx', 'fraud', 'freak', 'freaki', 'fredericksburg', 'free', 'free2day', 'freedom', 'freeentri', 'freefon', 'freek', 'freeli', 'freemessag', 'freemsg', 'freemsgfav', 'freemsgfeelin', 'freenokia', 'freephon', 'freerington', 'freeringtonerepli', 'freesend', 'freez', 'freind', 'fren', 'french', 'frequent', 'fresh', 'fresher', 'fret', 'fri', 'friday', 'fridayhop', 'fridg', 'friend', 'friendofafriend', 'friendsar', 'friendship', 'friendshipmotherfatherteacherschildren', 'fring', 'frm', 'frmcloud', 'frnd', 'frndship', 'frndshp', 'frndsship', 'frndz', 'frnt', 'fro', 'frog', 'frogaxel', 'from', 'fromm', 'fromwrk', 'front', 'frontiervil', 'frosti', 'fruit', 'frwd', 'ft', 'fuck', 'fuckin', 'fuckinniceselfishdeviousbitchanywayi', 'fudg', 'fuell', 'fujitsu', 'ful', 'fulfil', 'full', 'fullonsmscom', 'fumbl', 'fun', 'function', 'fund', 'fundament', 'funer', 'funk', 'funki', 'funni', 'furnitur', 'fusion', 'futur', 'fuuuuck', 'fwiw', 'fyi', 'g', 'g696ga', 'ga', 'gail', 'gailxx', 'gain', 'gal', 'galcan', 'galileo', 'galno', 'galsu', 'gam', 'game', 'gamestar', 'gandhipuram', 'ganesh', 'gang', 'gap', 'garag', 'garbag', 'garden', 'gari', 'garment', 'gastroenter', 'gate', 'gaug', 'gautham', 'gave', 'gay', 'gayd', 'gayl', 'gaytextbuddycom', 'gaze', 'gbp', 'gbp150week', 'gbp450week', 'gbp5month', 'gbpsm', 'gbpweek', 'gd', 'gdeve', 'gdnow', 'gdthe', 'ge', 'gee', 'geeee', 'geeeee', 'geelat', 'gei', 'gek1510', 'gender', 'gene', 'gener', 'geniu', 'gent', 'gentl', 'gentleman', 'gentli', 'genu', 'genuin', 'geoenvironment', 'georg', 'gep', 'ger', 'germani', 'get', 'get4an18th', 'gete', 'geti', 'getsleep', 'getstop', 'gettin', 'getzedcouk', 'gf', 'ghodbandar', 'ghost', 'gibb', 'gibe', 'gift', 'giggl', 'gigolo', 'gimm', 'gimmi', 'gin', 'girl', 'girld', 'girlfrnd', 'girli', 'gist', 'giv', 'give', 'given', 'givit', 'glad', 'gland', 'glasgow', 'glass', 'glo', 'global', 'glori', 'gloriou', 'gloucesterroad', 'gmgngegn', 'gmgngegnt', 'gmw', 'gnarl', 'go', 'go2', 'go2sri', 'goa', 'goal', 'goalsteam', 'gobi', 'god', 'godi', 'godnot', 'godtaken', 'godyou', 'goe', 'goggl', 'goigng', 'goin', 'goin2b', 'gokila', 'gold', 'golddigg', 'golden', 'goldvik', 'golf', 'gon', 'gona', 'gone', 'goneu', 'gong', 'gonna', 'gonnamissu', 'good', 'gooddhanush', 'goodenviron', 'goodeven', 'goodfin', 'goodfriend', 'goodi', 'goodmat', 'goodmorn', 'goodmorningmi', 'goodnight', 'goodnit', 'goodno', 'goodnoon', 'goodo', 'goodtimeoli', 'goodwhen', 'googl', 'gopalettan', 'gorgeou', 'gosh', 'gossip', 'gossx', 'got', 'gota', 'gotani', 'gotmarri', 'goto', 'gotta', 'gotten', 'gotto', 'gover', 'govtinstituit', 'gowait', 'gower', 'gpr', 'gpu', 'gr8', 'gr8fun', 'gr8prize', 'grab', 'grace', 'graduat', 'grahmbel', 'gram', 'gran', 'grand', 'grandfath', 'grandma', 'granit', 'grant', 'graphic', 'grasp', 'grate', 'grave', 'gravel', 'gravi', 'graviti', 'gray', 'graze', 'gre', 'great', 'greatbhaji', 'greatby', 'greatest', 'greatli', 'greec', 'green', 'greeni', 'greet', 'grief', 'grin', 'grinder', 'grinul', 'grl', 'grocer', 'groov', 'groovi', 'ground', 'groundamla', 'group', 'grow', 'grown', 'grownup', 'growrandom', 'grr', 'grumbl', 'grumpi', 'gs', 'gsex', 'gsoh', 'gt', 'gua', 'guai', 'guarante', 'gucci', 'gud', 'gudk', 'gudni8', 'gudnit', 'gudnitetcpractic', 'gudnyt', 'guess', 'guessin', 'guid', 'guidanc', 'guild', 'guilti', 'guitar', 'gumbi', 'guoyang', 'gurl', 'gut', 'guy', 'gv', 'gving', 'gwr', 'gym', 'gymnast', 'gyna', 'gyno', 'h', 'ha', 'habbahw', 'habit', 'hack', 'had', 'hadnt', 'hadya', 'haf', 'haha', 'hahahaus', 'hahatak', 'hai', 'hail', 'hair', 'haircut', 'hairdress', 'haiyoh', 'haiz', 'half', 'half8th', 'hall', 'halla', 'hallaq', 'halloween', 'ham', 'hamper', 'hamster', 'hand', 'handl', 'handset', 'handsom', 'hang', 'hanger', 'hangin', 'hank', 'hannaford', 'hanumanji', 'happen', 'happend', 'happenin', 'happi', 'happier', 'happiest', 'happili', 'hard', 'hardcor', 'harder', 'hardest', 'hardli', 'hari', 'harish', 'harlem', 'harri', 'hasbroin', 'hasnt', 'hassl', 'hat', 'hate', 'haughaighgtujhyguj', 'haul', 'haunt', 'hav', 'hav2hear', 'hava', 'havbeen', 'have', 'havebeen', 'havent', 'haventcn', 'havin', 'havnt', 'hcl', 'hdd', 'he', 'head', 'headach', 'headin', 'headset', 'headstart', 'heal', 'healer', 'healthi', 'heap', 'hear', 'heard', 'hearin', 'heart', 'heartgn', 'heartheart', 'heartsnot', 'heat', 'heater', 'heaven', 'heavi', 'heavili', 'hectic', 'hee', 'heehe', 'hehe', 'height', 'held', 'helen', 'hell', 'hella', 'hello', 'hellodrivby0quit', 'hellogorg', 'hellohow', 'helloooo', 'helloy', 'help', 'help08700469649', 'help08700621170150p', 'help08712400602450p', 'help08714742804', 'help08718728876', 'helplin', 'heltiniiyo', 'hen', 'henc', 'henri', 'hep', 'her', 'here', 'herepl', 'hererememb', 'herethanksi', 'heri', 'herlov', 'hermi', 'hero', 'heroi', 'heron', 'hersh', 'herwho', 'herwil', 'hesit', 'hex', 'hey', 'heygreat', 'hgsuite3422land', 'hgsuite3422landsroww1j6hl', 'hhahhaahahah', 'hi', 'hict', 'hidden', 'hide', 'hidid', 'high', 'highest', 'hii', 'hilariousalso', 'hill', 'hillsborough', 'him', 'himso', 'himthen', 'hint', 'hip', 'hiphop', 'hire', 'hisher', 'histori', 'hit', 'hitechn', 'hitler', 'hitman', 'hitteranyway', 'hittng', 'hiwhat', 'hiya', 'hlday', 'hlp', 'hme', 'hmm', 'hmmbad', 'hmmm', 'hmmmbut', 'hmmmhow', 'hmmmi', 'hmmmkbut', 'hmmmm', 'hmmmstill', 'hmph', 'hmv', 'hmv1', 'ho', 'hockey', 'hogidhechinnu', 'hogli', 'hogolo', 'hol', 'holbi', 'hold', 'holder', 'hole', 'holi', 'holiday', 'holidayso', 'holla', 'hollalat', 'home', 'homebut', 'homecheck', 'homeleft', 'homelov', 'homeown', 'homewot', 'hon', 'honest', 'honesti', 'honestli', 'honey', 'honeybe', 'honeydid', 'honeymoon', 'honi', 'hont', 'hoo', 'hooch', 'hoodi', 'hook', 'hoop', 'hop', 'hope', 'hopeafternoon', 'hopeso', 'hopeu', 'hor', 'horni', 'horniest', 'horo', 'horribl', 'hors', 'hospit', 'hostbas', 'hostel', 'hostil', 'hot', 'hotel', 'hotmix', 'hottest', 'hour', 'hourish', 'hous', 'housemaid', 'housew', 'housework', 'how', 'howard', 'howda', 'howdi', 'howev', 'howr', 'howu', 'howv', 'howz', 'hp', 'hp20', 'hppnss', 'hr', 'hrishi', 'hsbc', 'html', 'httpalto18coukwavewaveaspo44345', 'httpcareer', 'httpdoit', 'httpgotbabescouk', 'httpimg', 'httptm', 'httpwap', 'httpwwwbubbletextcom', 'httpwwwetlpcoukexpressoff', 'httpwwwetlpcoukreward', 'httpwwwgr8prizescom', 'httpwwwurawinnercom', 'httpwwwwtlpcouktext', 'huai', 'hubbi', 'hudgi', 'hug', 'huge', 'hugh', 'huh', 'hui', 'huim', 'hum', 'human', 'hun', 'hundr', 'hundredh', 'hungov', 'hungri', 'hunk', 'hunlov', 'hunni', 'hunnyhop', 'hunnyjust', 'hunnywot', 'hunonbu', 'hunt', 'hurri', 'hurrican', 'hurt', 'husband', 'hussey', 'hustl', 'hut', 'hv', 'hvae', 'hw', 'hwd', 'hwkeep', 'hyde', 'hypertens', 'hypotheticalhuagauahahuagahyuhagga', 'iZ', 'ia', 'iam', 'ibh', 'ibhltd', 'ibiza', 'ibm', 'ibn', 'ibor', 'ibuprofen', 'ic', 'iccha', 'ice', 'icic', 'icicibankcom', 'icki', 'icon', 'id', 'idc', 'idconvey', 'idea', 'ideal', 'identif', 'identifi', 'idiot', 'idk', 'idp', 'idu', 'ie', 'iff', 'ifink', 'ifwhenhow', 'ig11', 'ignor', 'ijust', 'ikea', 'ikno', 'iknow', 'il', 'ileav', 'ill', 'illspeak', 'ilol', 'im', 'ima', 'imag', 'imagin', 'imaginationmi', 'imat', 'imf', 'imin', 'imma', 'immedi', 'immunis', 'imp', 'impati', 'implic', 'import', 'importantli', 'impos', 'imposs', 'impost', 'impress', 'improv', 'imprtant', 'in2', 'inc', 'inch', 'incid', 'inclu', 'includ', 'inclus', 'incomm', 'inconsider', 'inconveni', 'incorrect', 'increas', 'incred', 'increment', 'ind', 'inde', 'independ', 'india', 'indian', 'indianpl', 'indic', 'individu', 'individualtim', 'indyarockscom', 'inev', 'infact', 'infect', 'infern', 'influx', 'info', 'inforingtonekingcouk', 'inform', 'informedrgdsrakheshkerala', 'infotxt82228couk', 'infovipclub4u', 'infowww100percentrealcom', 'infra', 'infront', 'ing', 'ingredi', 'initi', 'ink', 'inlud', 'inmind', 'inner', 'inning', 'innoc', 'innu', 'inour', 'inperialmus', 'inperson', 'inr', 'insect', 'insha', 'inshah', 'insid', 'inspect', 'inst', 'instal', 'instant', 'instantli', 'instead', 'instruct', 'insur', 'intellig', 'intend', 'intent', 'interest', 'interflora', 'interfu', 'intern', 'internet', 'internetservic', 'interview', 'interviw', 'intha', 'intim', 'into', 'intrepid', 'intro', 'intrud', 'invad', 'invent', 'invest', 'investig', 'invit', 'invnt', 'invoic', 'involv', 'iouri', 'ip', 'ip4', 'ipad', 'ipaditan', 'iphon', 'ipod', 'iraq', 'ireneer', 'iriv', 'iron', 'irrit', 'irulina', 'isaiahd', 'isar', 'iscom', 'ish', 'ishtamayoohappi', 'island', 'islov', 'isnt', 'issu', 'isvimport', 'it', 'italian', 'itboth', 'itc', 'itcould', 'item', 'iter', 'ithi', 'ithink', 'iti', 'itjust', 'itleav', 'itlet', 'itll', 'itmail', 'itmay', 'itna', 'itnow', 'itor', 'itplspl', 'itried2tel', 'itsnot', 'ittb', 'itu', 'itwhichturnedinto', 'itxt', 'itxx', 'itz', 'ivatt', 'ive', 'iwana', 'iwasmarinethat', 'iz', 'izzit', 'j', 'j89', 'jabo', 'jack', 'jacket', 'jackpot', 'jackson', 'jacuzzi', 'jada', 'jade', 'jaklin', 'jam', 'jame', 'jamster', 'jamstercouk', 'jamsterget', 'jamz', 'jan', 'janarig', 'jane', 'janinexx', 'januari', 'janx', 'jap', 'japanes', 'jason', 'java', 'jay', 'jaya', 'jaykwon', 'jaz', 'jazz', 'jb', 'je', 'jealou', 'jean', 'jeetey', 'jeevithathil', 'jelli', 'jen', 'jenn', 'jenni', 'jenxxx', 'jeremiah', 'jeri', 'jerk', 'jerri', 'jersey', 'jess', 'jesu', 'jet', 'jetton', 'jewelri', 'jez', 'ji', 'jia', 'jiayin', 'jide', 'jiu', 'jjc', 'jo', 'joanna', 'job', 'jobyet', 'jock', 'jod', 'jog', 'john', 'join', 'joinedhop', 'joinedso', 'joke', 'joker', 'jokethet', 'jokin', 'jolli', 'jolt', 'jon', 'jone', 'jontin', 'jordan', 'jordantxt', 'jorgeshock', 'jot', 'journey', 'joy', 'jp', 'js', 'jsco', 'jst', 'jstfrnd', 'jsut', 'ju', 'juan', 'judgementali', 'juici', 'jule', 'juli', 'juliana', 'julianaland', 'jump', 'jumper', 'june', 'jungl', 'junna', 'jurong', 'just', 'justbeen', 'justifi', 'justthought', 'juswok', 'juz', 'k', 'k52', 'k61', 'k718', 'kaaj', 'kadeem', 'kafter', 'kaiez', 'kaila', 'kaitlyn', 'kalaachutaarama', 'kalainar', 'kalisidar', 'kall', 'kalli', 'kalstiyathen', 'kama', 'kanagu', 'kane', 'kanji', 'kano', 'kanoanyway', 'kanoil', 'kanowhr', 'kappa', 'karaok', 'karnan', 'karo', 'kate', 'katexxx', 'kath', 'kavalan', 'kay', 'kaypoh', 'kb', 'kbut', 'kdo', 'ke', 'keen', 'keep', 'keepintouch', 'kegger', 'keluviri', 'ken', 'keng', 'kent', 'kept', 'kerala', 'keralacircl', 'keri', 'kettoda', 'key', 'keypad', 'keyword', 'kfc', 'kg', 'kgive', 'kgood', 'khelat', 'ki', 'kicchu', 'kick', 'kickbox', 'kickoff', 'kid', 'kidz', 'kill', 'kilo', 'kim', 'kind', 'kinda', 'kindli', 'king', 'kingdom', 'kintu', 'kiosk', 'kip', 'kisi', 'kiss', 'kit', 'kitti', 'kittum', 'kkadvanc', 'kkani', 'kkapo', 'kkare', 'kkcongratul', 'kkfrom', 'kkgoodstudi', 'kkhow', 'kkim', 'kkit', 'kkthi', 'kkwhat', 'kkwhen', 'kkwhere', 'kkwhi', 'kkyesterday', 'kl341', 'knacker', 'knee', 'knew', 'knicker', 'knock', 'know', 'knowh', 'known', 'knowneway', 'knowthi', 'knowwait', 'knowyetund', 'knw', 'ko', 'kochi', 'kodstini', 'kodthini', 'konw', 'korch', 'korean', 'korli', 'kort', 'kote', 'kothi', 'ksri', 'kthen', 'ktv', 'kuch', 'kudiyarasu', 'kusruthi', 'kvb', 'kwish', 'kyou', 'kz', 'l8', 'l8er', 'l8r', 'l8tr', 'la', 'la1', 'la3', 'la32wu', 'lab', 'labor', 'lac', 'lack', 'lacsthat', 'lacsther', 'laden', 'ladi', 'ladiesu', 'lag', 'lage', 'lager', 'laid', 'laidwant', 'lakh', 'lambda', 'lambu', 'lamp', 'lancast', 'land', 'landlin', 'landlineonli', 'landmark', 'lane', 'langport', 'languag', 'lanka', 'lanr', 'lap', 'lapdanc', 'laptop', 'lar', 'lara', 'lareadi', 'larg', 'largest', 'lark', 'lasagna', 'last', 'lastest', 'late', 'latebut', 'latei', 'latelyxxx', 'later', 'lateso', 'latest', 'latr', 'laugh', 'laundri', 'lauri', 'lautech', 'lavend', 'law', 'laxinorf', 'lay', 'layin', 'lazi', 'lccltd', 'ldn', 'ldnw15h', 'le', 'lead', 'leadership', 'leafcutt', 'leafdayno', 'leagu', 'leannewhat', 'learn', 'least', 'least5tim', 'leastwhich', 'leav', 'lect', 'lectur', 'left', 'leftov', 'leg', 'legal', 'legitimat', 'leh', 'lehhaha', 'lei', 'lekdog', 'lemm', 'length', 'lennon', 'leo', 'leona', 'leonardo', 'less', 'lesser', 'lesson', 'let', 'letter', 'leu', 'level', 'li', 'liao', 'liaoso', 'liaotoo', 'lib', 'libertin', 'librari', 'lick', 'lido', 'lie', 'life', 'lifeand', 'lifebook', 'lifei', 'lifethi', 'lifetim', 'lifey', 'lifpartnr', 'lift', 'light', 'lighter', 'lightli', 'lik', 'like', 'likeyour', 'likingb', 'lil', 'lili', 'lim', 'limit', 'limp', 'lindsay', 'line', 'linear', 'linerent', 'liney', 'lingeri', 'lingo', 'link', 'linux', 'lion', 'lionm', 'lionp', 'lip', 'lipo', 'liquor', 'list', 'listen', 'listening2th', 'listn', 'lit', 'liter', 'litr', 'littl', 'live', 'liver', 'liverpool', 'lk', 'lkpobox177hp51fl', 'llspeak', 'lm', 'lmao', 'lmaonic', 'lnli', 'lo', 'load', 'loan', 'lobbi', 'local', 'locat', 'locaxx', 'lock', 'lodg', 'log', 'login', 'logo', 'logoff', 'logon', 'logop', 'logosmusicnew', 'loko', 'lol', 'lolnic', 'lololo', 'londn', 'london', 'lone', 'loneli', 'long', 'longer', 'lonlin', 'loo', 'look', 'lookatm', 'lookin', 'lool', 'loooooool', 'looovvv', 'loos', 'loosu', 'lor', 'lord', 'lorgoin', 'lorw', 'lose', 'loser', 'loss', 'lost', 'lot', 'loti', 'lotr', 'lotsli', 'lotsof', 'lotta', 'lotto', 'lotwil', 'lotz', 'lou', 'loud', 'loung', 'lousi', 'lov', 'lovabl', 'love', 'loveabl', 'lovejen', 'lovem', 'lover', 'loverakhesh', 'loverboy', 'lovin', 'lovingli', 'lovli', 'low', 'lowcost', 'lower', 'loxahatche', 'loyal', 'loyalti', 'lrg', 'ls1', 'ls15hb', 'ls278bb', 'lst', 'lt', 'lt3', 'ltd', 'ltdecimalgt', 'ltdhelpdesk', 'ltemailgt', 'ltgt', 'lttimegt', 'lttr', 'lturlgt', 'lubli', 'luci', 'luck', 'luck2', 'lucki', 'luckili', 'lucozad', 'lucozadecoukwrc', 'lucyxx', 'luk', 'lul', 'lunch', 'lunchtim', 'lunchyou', 'lunsford', 'lush', 'luton', 'luv', 'luvd', 'luvnight', 'lux', 'luxuri', 'lv', 'lvblefrnd', 'lyf', 'lyfu', 'lyk', 'lyric', 'lyricalladie21f', 'm100', 'm221bp', 'm227xi', 'm26', 'm263uz', 'm39m51', 'm8', 'm95', 'ma', 'maaaan', 'maangalyam', 'maat', 'mac', 'macedonia', 'macha', 'machan', 'machiani', 'machin', 'macho', 'mack', 'macleran', 'mad', 'mad1', 'mad2', 'madam', 'madamregret', 'made', 'madodu', 'madok', 'madstini', 'madthen', 'mag', 'maga', 'magazin', 'maggi', 'magic', 'magicalsongsblogspotcom', 'mah', 'mahal', 'mahfuuzmean', 'mail', 'mailbox', 'maili', 'main', 'maintain', 'major', 'make', 'maki', 'makin', 'malaria', 'malarki', 'male', 'mall', 'mallika', 'man', 'manag', 'manchest', 'manda', 'mandan', 'mandara', 'mandi', 'maneesha', 'maneg', 'mango', 'mani', 'maniac', 'manki', 'manual', 'map', 'mapquest', 'maraikara', 'marandratha', 'march', 'maretar', 'margaret', 'margin', 'mari', 'mark', 'market', 'marley', 'marrgeremembr', 'marri', 'marriag', 'marriageprogram', 'marsm', 'marvel', 'mask', 'massag', 'massagetiepo', 'massiv', 'master', 'masteriast', 'mat', 'match', 'mate', 'math', 'mathemat', 'mathew', 'matra', 'matric', 'matrix3', 'matter', 'mattermsg', 'matthew', 'matur', 'max', 'max10min', 'max6month', 'maxim', 'maximum', 'may', 'mayb', 'mb', 'mc', 'mca', 'mcat', 'mcr', 'meal', 'mean', 'meaning', 'meaningless', 'meant', 'meanwhil', 'mear', 'measur', 'meat', 'meatbal', 'mecaus', 'med', 'medic', 'medicin', 'medont', 'mee', 'meet', 'meetgreet', 'meetin', 'meetitz', 'mega', 'meh', 'mei', 'meim', 'meiv', 'mel', 'melik', 'mell', 'melnit', 'melodi', 'melt', 'member', 'membership', 'membershiptak', 'memor', 'memori', 'men', 'mene', 'mental', 'mention', 'mentionedtomorrow', 'mentor', 'menu', 'meok', 'meow', 'meowd', 'mere', 'merememberin', 'meremov', 'merri', 'mesag', 'mesh', 'meso', 'mess', 'messag', 'messageit', 'messageno', 'messagepandi', 'messagesim', 'messagesom', 'messagestext', 'messagethank', 'messeng', 'messi', 'met', 'method', 'meummifyingby', 'mfl', 'mg', 'mi', 'mia', 'michael', 'mid', 'middl', 'midnight', 'might', 'miiiiiiissssssssss', 'mila', 'mile', 'mileag', 'milk', 'milkdayno', 'miller', 'million', 'miltazindgi', 'min', 'mina', 'minapn', 'mind', 'mindi', 'mindsetbeliev', 'mine', 'mineal', 'minecraft', 'mini', 'minimum', 'minnaminungint', 'minor', 'mins100txtmth', 'minstand', 'minstext', 'mint', 'minu', 'minut', 'miracl', 'mirror', 'misbehav', 'mise', 'miser', 'misfit', 'misplac', 'miss', 'misscal', 'missi', 'missin', 'mission', 'missionari', 'misss', 'misstak', 'missunderstd', 'mist', 'mistak', 'mistakeu', 'misundrstud', 'mite', 'mitsak', 'mittelschmertz', 'miwa', 'mix', 'mj', 'mjzgroup', 'mk17', 'mk45', 'ml', 'mmm', 'mmmm', 'mmmmm', 'mmmmmm', 'mmmmmmm', 'mmsto', 'mn', 'mnth', 'mo', 'moan', 'mob', 'mobcudb', 'mobi', 'mobil', 'mobilesdirect', 'mobilesvari', 'mobileupd8', 'mobno', 'mobsicom', 'mobstorequiz10ppm', 'mode', 'model', 'modelsoni', 'modl', 'modul', 'mofo', 'moji', 'mojibiola', 'mokka', 'molestedsomeon', 'mom', 'moment', 'mon', 'monday', 'mondaynxt', 'moneeppolum', 'money', 'moneya', 'moneyi', 'monkeespeopl', 'monkey', 'monkeyaround', 'monl8rsx', 'mono', 'monoc', 'monster', 'month', 'monthli', 'monthlysubscription50pmsg', 'monthnot', 'mood', 'moon', 'moral', 'moraldont', 'moralon', 'more', 'morn', 'mornin', 'morningtak', 'morphin', 'morrow', 'moseley', 'most', 'mostli', 'mother', 'motherfuck', 'motherinlaw', 'motiv', 'motor', 'motorola', 'mountain', 'mous', 'mouth', 'move', 'movi', 'moviewat', 'moyep', 'mp3', 'mquiz', 'mr', 'mre', 'mrng', 'mrt', 'mrur', 'ms', 'msg', 'msg150p', 'msging', 'msgrcvd18', 'msgs150p', 'msgsd', 'msgsometext', 'msgsubscript', 'msgticketkioskvalid', 'msgwe', 'msn', 'mssuman', 'mt', 'mtalk', 'mth', 'mtnl', 'mu', 'much', 'muchand', 'muchi', 'muchimped', 'muchxxlov', 'mudyadhu', 'mufti', 'muhommad', 'muht', 'multi', 'multimedia', 'multipli', 'mum', 'mumbai', 'mumha', 'mummi', 'mumtaz', 'mundh', 'munster', 'murali', 'murder', 'mush', 'mushi', 'music', 'must', 'musta', 'musthu', 'mustprovid', 'mutai', 'mutat', 'muz', 'mw', 'mwah', 'my', 'mycallsu', 'mylif', 'mymobi', 'mypar', 'myself', 'myspac', 'mysteri', 'mytonecomenjoy', 'n', 'n8', 'na', 'naal', 'nacho', 'nag', 'nagar', 'nah', 'nahi', 'nail', 'nake', 'nalla', 'nalli', 'name', 'name1', 'name2', 'namemi', 'nammanna', 'nan', 'nang', 'nanni', 'nap', 'narcot', 'nasdaq', 'naseeb', 'nasti', 'nat', 'natali', 'natalja', 'nation', 'nationwid', 'nattil', 'natuit', 'natur', 'natwest', 'naughti', 'nauseou', 'nav', 'navig', 'nb', 'nbme', 'nd', 'ne', 'near', 'nearbi', 'nearer', 'nearli', 'neces', 'necess', 'necessari', 'necessarili', 'neck', 'necklac', 'ned', 'need', 'needa', 'neededsalari', 'needi', 'needl', 'neekunna', 'neft', 'neg', 'neglect', 'neglet', 'neighbor', 'neither', 'nelson', 'neo69', 'nervou', 'neshanthtel', 'net', 'netcollex', 'netflix', 'neth', 'netno', 'network', 'neva', 'nevamindw', 'never', 'nevil', 'nevr', 'new', 'neway', 'newest', 'newport', 'newquaysend', 'news', 'newsbi', 'newscast', 'newshyp', 'newspap', 'next', 'ngage', 'nh', 'ni8', 'ni8swt', 'nic', 'nice', 'nicenicehow', 'nichol', 'nick', 'nickey', 'nicki', 'nig', 'nigeria', 'nigh', 'night', 'nighter', 'nightnight', 'nightnobodi', 'nightsexcel', 'nightsw', 'nightswt', 'nigpun', 'nigro', 'nike', 'nikiyu4net', 'nimbomson', 'nimya', 'nimyapl', 'ninish', 'nino', 'nipost', 'nit', 'nite', 'nite2', 'nitro', 'nitw', 'nitz', 'njan', 'nmde', 'no', 'no1', 'no165', 'no434', 'no440', 'no762', 'no81151', 'no83355', 'no910', 'nob', 'nobl', 'nobodi', 'nobut', 'noe', 'nofew', 'nohe', 'noi', 'noic', 'nois', 'noisi', 'noit', 'nojst', 'nok', 'nokia', 'nokia150p', 'nokia6600', 'nokia6650', 'nolin', 'nolistened2th', 'non', 'noncomitt', 'none', 'nonenowher', 'nonetheless', 'nookii', 'noon', 'nooooooo', 'noooooooo', 'nope', 'nora', 'norcorp', 'nordstrom', 'norm', 'norm150pton', 'normal', 'north', 'northampton', 'nose', 'nosh', 'nosi', 'not', 'note', 'notebook', 'noth', 'nothi', 'nothin', 'notic', 'notif', 'notifi', 'notixiqu', 'nottel', 'nottingham', 'notxtcouk', 'noun', 'novelti', 'novemb', 'now', 'now1', 'now4t', 'nowaday', 'nowadayslot', 'nowcan', 'nowi', 'nownyt', 'nowonion', 'noworriesloanscom', 'nowrepli', 'nowsavamobmemb', 'nowsend', 'nowski', 'nowstil', 'nowtc', 'nowus', 'nr31', 'nri', 'nt', 'nte', 'ntswt', 'ntt', 'ntwk', 'nu', 'nuclear', 'nudist', 'nuerologist', 'num', 'number', 'numberpl', 'numberrespect', 'numberso', 'nurs', 'nurseri', 'nurungu', 'nusstu', 'nuther', 'nutter', 'nver', 'nvm', 'nvq', 'nw', 'nxt', 'ny', 'nyc', 'nydc', 'nyt', 'nytec2a3lpmsg150p', 'nytho', 'nyusa', 'nz', 'nìte', 'o2coukgam', 'o2fwd', 'oath', 'obedi', 'obes', 'obey', 'object', 'oblising', 'oblivi', 'obvious', 'occas', 'occupi', 'occur', 'oceand', 'oclock', 'octob', 'odalebeku', 'odi', 'ofcours', 'off', 'offc', 'offcampu', 'offdam', 'offens', 'offer', 'offerth', 'offic', 'officestil', 'officethenampet', 'officeunderstand', 'officewhat', 'offici', 'offlin', 'ofic', 'oficegot', 'ofsi', 'often', 'oga', 'ogunrind', 'oh', 'oha', 'ohi', 'oic', 'oil', 'oja', 'ok', 'okay', 'okcom', 'okday', 'okden', 'okey', 'oki', 'okmail', 'okok', 'okor', 'oktak', 'okthenwhat', 'okvarunnathu', 'ola', 'olag', 'olav', 'olayiwola', 'old', 'ollubut', 'olol', 'olowoyey', 'olymp', 'omg', 'omw', 'onam', 'onc', 'oncal', 'ondu', 'one', 'onedg', 'oneta', 'oni', 'onionr', 'onit', 'onli', 'onlin', 'onlinewhi', 'onluy', 'only1mor', 'onlybettr', 'onlydon', 'onlyfound', 'onto', 'onum', 'onward', 'onword', 'ooh', 'oooh', 'oooooh', 'ooooooh', 'oop', 'open', 'openin', 'oper', 'opinion', 'opp', 'opponent', 'opportun', 'opportunityal', 'opportunitypl', 'oppos', 'opposit', 'opt', 'optimist', 'optin', 'option', 'optout', 'or', 'or2optouthv9d', 'or2stoptxt', 'oral', 'orang', 'orangei', 'orc', 'orchard', 'order', 'ore', 'oredi', 'oreo', 'organ', 'organis', 'orh', 'orig', 'origin', 'orno', 'ortxt', 'oru', 'os', 'oscar', 'oso', 'otbox', 'other', 'otherwis', 'othr', 'otsid', 'ou', 'ouch', 'our', 'ourback', 'oursso', 'out', 'outag', 'outbid', 'outdoor', 'outfit', 'outfor', 'outgo', 'outhav', 'outif', 'outl8rjust', 'outrag', 'outreach', 'outsid', 'outsomewher', 'outstand', 'outta', 'ovarian', 'over', 'overa', 'overdid', 'overdos', 'overemphasiseor', 'overh', 'overtim', 'ovr', 'ovul', 'ovulatewhen', 'ow', 'owe', 'owl', 'own', 'ownyouv', 'owo', 'oxygen', 'oyea', 'oyster', 'oz', 'p', 'pa', 'pace', 'pack', 'packag', 'packalso', 'padhegm', 'page', 'pai', 'paid', 'pain', 'painhop', 'painit', 'paint', 'pale', 'palm', 'pan', 'panalambut', 'panason', 'pandi', 'panic', 'panick', 'panren', 'pansi', 'pant', 'panther', 'panti', 'pap', 'papa', 'paper', 'paperwork', 'paracetamol', 'parachut', 'parad', 'paragon', 'paragraph', 'paranoid', 'parantella', 'parchi', 'parco', 'parent', 'parentnot', 'parentsi', 'pari', 'parisfre', 'parish', 'park', 'park6ph', 'parkin', 'part', 'parti', 'particip', 'particular', 'particularli', 'partner', 'partnership', 'paru', 'pase', 'pass', 'passabl', 'passion', 'passport', 'passthey', 'password', 'passwordsatmsm', 'past', 'pataistha', 'patent', 'path', 'pathaya', 'patient', 'patrick', 'pattern', 'patti', 'paul', 'paus', 'pay', 'payasam', 'payback', 'paye', 'payed2day', 'payment', 'payoh', 'paypal', 'pc', 'pdatenow', 'peac', 'peach', 'peak', 'pear', 'pee', 'peep', 'pehl', 'pei', 'pen', 'penc', 'pend', 'pendent', 'pendingi', 'peni', 'penni', 'peopl', 'per', 'percent', 'percentag', 'perf', 'perfect', 'perform', 'perfum', 'perhap', 'peril', 'period', 'peripher', 'perman', 'permiss', 'perpetu', 'persev', 'persian', 'person', 'person2di', 'personmeet', 'perspect', 'perumbavoor', 'peski', 'pest', 'pete', 'petei', 'petexxx', 'petey', 'peteynoi', 'petrol', 'petrolr', 'pg', 'ph', 'ph08700435505150p', 'ph08704050406', 'pharmaci', 'phase', 'phd', 'phew', 'phil', 'philosoph', 'philosophi', 'phne', 'phoenix', 'phone', 'phone750', 'phonebook', 'phoni', 'photo', 'photoshop', 'php', 'phrase', 'physic', 'piah', 'pic', 'pick', 'pickl', 'picsfree1', 'pictur', 'pictxt', 'pie', 'piec', 'pierr', 'pig', 'piggi', 'pilat', 'pile', 'pillow', 'pimpl', 'pimpleseven', 'pin', 'pink', 'pinku', 'pint', 'pisc', 'piss', 'piti', 'pix', 'pixel', 'pizza', 'pl', 'place', 'placement', 'placeno', 'plaid', 'plan', 'plane', 'planet', 'planeti', 'planettalkinstantcom', 'plate', 'platt', 'play', 'player', 'playerwhi', 'playi', 'playin', 'playng', 'plaza', 'pleas', 'pleasant', 'pleassssssseeeee', 'pleasur', 'plenti', 'plm', 'plough', 'plsi', 'plu', 'plum', 'plumber', 'plumbingremix', 'plural', 'plyr', 'plz', 'pm', 'pmt', 'po', 'po19', 'pobox', 'pobox1', 'pobox11414tcrw1', 'pobox12n146tf15', 'pobox12n146tf150p', 'pobox202', 'pobox334', 'pobox36504w45wq', 'pobox365o4w45wq', 'pobox45w2tg150p', 'pobox75ldns7', 'pobox84', 'poboxox36504w45wq', 'pocay', 'poci', 'pock', 'pocket', 'pocketbabecouk', 'pod', 'poem', 'poet', 'point', 'poke', 'poker', 'pokkiri', 'pole', 'poli', 'polic', 'politician', 'polo', 'poly200p', 'poly3', 'polyc', 'polyh', 'polyph', 'polyphon', 'polytruepixringtonesgam', 'pongal', 'pongaldo', 'ponnungal', 'poo', 'pooki', 'pool', 'poop', 'poor', 'poorli', 'poortiyagi', 'pop', 'popcorn', 'popcornjust', 'porn', 'porridg', 'port', 'portal', 'porteg', 'portion', 'pose', 'posh', 'posibl', 'posit', 'possess', 'possibl', 'possiblehop', 'post', 'postal', 'postcard', 'postcod', 'posterod', 'postpon', 'potato', 'potenti', 'potter', 'pouch', 'pound', 'pour', 'pout', 'power', 'poyyarikaturkolathupalayamunjalur', 'ppl', 'pple', 'pple700', 'ppm', 'ppm150', 'ppt150x3normal', 'prabha', 'prabhaim', 'prabu', 'pract', 'practic', 'practicum', 'practis', 'prais', 'prakasam', 'prakasamanu', 'prakesh', 'prap', 'prasad', 'prasanth', 'prashanthettan', 'pray', 'prayer', 'prayingwil', 'prayr', 'pre', 'prebook', 'predict', 'prefer', 'prem', 'premaricakindli', 'premier', 'premium', 'prepaid', 'prepar', 'prepay', 'prepon', 'preschoolcoordin', 'prescrib', 'prescripiton', 'prescript', 'presenc', 'present', 'presid', 'presley', 'presnt', 'press', 'pressi', 'pressur', 'prestig', 'pretend', 'pretsorginta', 'pretsovru', 'pretti', 'prevent', 'preview', 'previou', 'previous', 'prey', 'price', 'priceso', 'pride', 'priest', 'prin', 'princ', 'princegn', 'princess', 'print', 'printer', 'prior', 'prioriti', 'priscilla', 'privaci', 'privat', 'prix', 'priya', 'prize', 'prizeawait', 'prizeswith', 'prizeto', 'pro', 'prob', 'probabl', 'problem', 'problemat', 'problembut', 'problemfre', 'problemi', 'problm', 'problum', 'probthat', 'process', 'processexcel', 'processit', 'processnetwork', 'prod', 'product', 'prof', 'profession', 'professor', 'profil', 'profit', 'program', 'progress', 'project', 'prolli', 'prometazin', 'promin', 'promis', 'promo', 'promot', 'prompt', 'promptli', 'prone', 'proof', 'proov', 'prop', 'proper', 'properli', 'properti', 'propos', 'propsd', 'prospect', 'protect', 'prove', 'proverb', 'provid', 'provinc', 'proze', 'prsn', 'ps3', 'pshewmiss', 'psp', 'psxtra', 'psychiatrist', 'psychic', 'psychologist', 'pt2', 'ptbo', 'pthi', 'pub', 'pubcaf', 'public', 'publish', 'pudunga', 'pull', 'pump', 'punch', 'punish', 'punto', 'puppi', 'pura', 'purchas', 'pure', 'puriti', 'purpleu', 'purpos', 'purs', 'push', 'pushbutton', 'pussi', 'put', 'puttin', 'puzzel', 'puzzl', 'px3748', 'qatar', 'qatarrakhesh', 'qbank', 'qet', 'qi', 'qing', 'qlynnbv', 'qualiti', 'quarter', 'que', 'queen', 'queri', 'question', 'questionstd', 'quick', 'quickli', 'quiet', 'quit', 'quiteamuz', 'quiz', 'quizclub', 'quizwin', 'quizz', 'quot', 'r', 'r836', 'ra', 'racal', 'race', 'radiat', 'radio', 'rael', 'raglan', 'rahul', 'raiden', 'railway', 'rain', 'rais', 'raj', 'raja', 'rajini', 'rajipl', 'rajitha', 'rajnik', 'rakhesh', 'raksha', 'ralli', 'ralph', 'ramen', 'ran', 'randi', 'random', 'randomli', 'randomlli', 'rang', 'ranjith', 'ranju', 'rape', 'rat', 'rate', 'ratetc', 'rather', 'ratio', 'raviyog', 'rawr', 'ray', 'rayan', 'rayman', 'rcbbattl', 'rcd', 'rct', 'rcv', 'rcvd', 'rd', 'rdi', 'reach', 'react', 'reaction', 'read', 'reader', 'readi', 'readyal', 'real', 'real1', 'reali', 'realis', 'realiti', 'realiz', 'realli', 'reallyne', 'reappli', 'rearrang', 'reason', 'reassur', 'rebel', 'reboot', 'rebtel', 'rec', 'recd', 'recdthirtyeight', 'receipt', 'receiv', 'receivea', 'recent', 'recept', 'recess', 'recharg', 'rechargerakhesh', 'reciev', 'reckon', 'recognis', 'record', 'recount', 'recoveri', 'recpt', 'recreat', 'recycl', 'red', 'redeem', 'redim', 'redr', 'reduc', 'ree', 'ref', 'ref9280114', 'ref9307622', 'refer', 'referin', 'reffer', 'refil', 'reflect', 'reflex', 'reformat', 'refresh', 'refund', 'refundedthi', 'refus', 'reg', 'regard', 'regist', 'registr', 'regret', 'regular', 'reject', 'rel', 'relat', 'relationshipit', 'relax', 'releas', 'reliant', 'reliev', 'religi', 'reloc', 'reltnship', 'rem', 'remain', 'remb', 'rememb', 'rememberi', 'remembr', 'remet', 'remind', 'remov', 'rencontr', 'renew', 'rent', 'rental', 'rentl', 'repair', 'repeat', 'repent', 'replac', 'repli', 'replyb', 'replys150', 'report', 'reppurcuss', 'repres', 'republ', 'request', 'requir', 'reschedul', 'research', 'resend', 'resent', 'reserv', 'reset', 'resid', 'resiz', 'reslov', 'resolut', 'resolv', 'resort', 'respect', 'responcewhat', 'respond', 'respons', 'rest', 'restaur', 'restock', 'restrict', 'restuwud', 'restwish', 'resub', 'resubmit', 'result', 'resum', 'retard', 'retir', 'retriev', 'return', 'reunion', 'reveal', 'revers', 'review', 'revis', 'reward', 'rg21', 'rgd', 'rgent', 'rhode', 'rhythm', 'rice', 'rich', 'riddanc', 'ridden', 'ride', 'right', 'rightio', 'rightli', 'riley', 'rimac', 'ring', 'ringsreturn', 'rington', 'ringtonefrom', 'ringtoneget', 'ringtonek', 'rinu', 'rip', 'rise', 'risk', 'rite', 'ritten', 'river', 'ro', 'road', 'roadsrvx', 'roast', 'rob', 'robinson', 'rock', 'rodds1', 'rodger', 'rofl', 'roger', 'role', 'roll', 'roller', 'romant', 'romcapspam', 'ron', 'room', 'roomat', 'roommat', 'rose', 'rough', 'round', 'rounderso', 'rout', 'row', 'roww1j6hl', 'roww1jhl', 'royal', 'rp176781', 'rpl', 'rpli', 'rr', 'rreveal', 'rs', 'rs5', 'rsi', 'rstm', 'rtking', 'rtm', 'rto', 'ru', 'rub', 'rubber', 'rude', 'rudi', 'rugbi', 'ruin', 'rule', 'rum', 'rumbl', 'rummer', 'rumour', 'run', 'runninglet', 'rupaul', 'rush', 'ryan', 'ryder', 's3xi', 's89', 'sac', 'sachin', 'sachinjust', 'sack', 'sacrific', 'sad', 'sae', 'saeed', 'safe', 'safeti', 'sagamu', 'saibaba', 'said', 'saidif', 'sake', 'salad', 'salam', 'salari', 'sale', 'salesman', 'salespe', 'sall', 'salmon', 'salon', 'salt', 'sam', 'samachara', 'samantha', 'sambarlif', 'same', 'sameso', 'samu', 'sandiago', 'sane', 'sang', 'sankranti', 'santa', 'santha', 'sao', 'sapna', 'sar', 'sara', 'sarasota', 'sarcasm', 'sarcast', 'sari', 'saristar', 'sariyag', 'sashimi', 'sat', 'satan', 'sathi', 'sathya', 'satisfi', 'satjust', 'satlov', 'satsgettin', 'satsound', 'satthen', 'saturday', 'satü', 'sauci', 'sausagelov', 'savamob', 'save', 'saw', 'say', 'sayask', 'sayhey', 'sayi', 'sayin', 'sbut', 'sc', 'scalli', 'scammer', 'scarcasim', 'scare', 'scari', 'scenario', 'sceneri', 'sch', 'schedul', 'school', 'scienc', 'scold', 'scool', 'scorabl', 'score', 'scotch', 'scotland', 'scotsman', 'scous', 'scrape', 'scrappi', 'scratch', 'scream', 'screen', 'screwd', 'scroung', 'scrumptiou', 'sculptur', 'sd', 'sday', 'sdryb8i', 'se', 'sea', 'search', 'season', 'seat', 'sec', 'second', 'secondari', 'secret', 'secretari', 'secretli', 'section', 'secur', 'sed', 'see', 'seed', 'seek', 'seeker', 'seem', 'seen', 'seeno', 'sef', 'seh', 'sehwag', 'select', 'self', 'selfindepend', 'selfish', 'selfless', 'sell', 'sem', 'semest', 'semi', 'semiobscur', 'sen', 'send', 'sender', 'sendernam', 'senor', 'senrddnot', 'sens', 'sensesrespect', 'sensibl', 'sensit', 'sent', 'sentdat', 'sentenc', 'senthil', 'senthilhsbc', 'seperated鈥', 'sept', 'septemb', 'serena', 'seri', 'seriou', 'serious', 'serv', 'server', 'servic', 'set', 'settl', 'seven', 'seventeen', 'sever', 'sex', 'sexi', 'sexiest', 'sextextukcom', 'sexual', 'sexychat', 'sez', 'sfine', 'sfirst', 'sfrom', 'sh', 'sha', 'shade', 'shadow', 'shag', 'shah', 'shahjahan', 'shakara', 'shake', 'shakespear', 'shall', 'shame', 'shampain', 'shangela', 'shanghai', 'shanilrakhesh', 'shant', 'shape', 'share', 'shatter', 'shave', 'shb', 'shd', 'she', 'sheet', 'sheffield', 'shelf', 'shell', 'shelv', 'sherawat', 'shesil', 'shexi', 'shhhhh', 'shi', 'shifad', 'shija', 'shijutta', 'shinco', 'shindig', 'shine', 'shini', 'ship', 'shirt', 'shit', 'shite', 'shitin', 'shitjustfound', 'shitload', 'shitstorm', 'shivratri', 'shja', 'shld', 'shldxxxx', 'shock', 'shoe', 'shola', 'shoot', 'shop', 'shoppin', 'shopth', 'shopw', 'shoranur', 'shore', 'shoreth', 'short', 'shortag', 'shortcod', 'shorter', 'shortli', 'shot', 'shoul', 'should', 'shoulder', 'shouldnt', 'shout', 'shove', 'show', 'shower', 'showr', 'showroomsc', 'shracomorsglsuplt10', 'shrek', 'shrink', 'shrub', 'shu', 'shud', 'shudvetold', 'shuhui', 'shun', 'shut', 'si', 'sian', 'sib', 'sic', 'sick', 'sicomo', 'side', 'sif', 'sigh', 'sight', 'sign', 'signal', 'signific', 'signin', 'siguviri', 'silenc', 'silent', 'silli', 'silver', 'sim', 'simonwatson5120', 'simpl', 'simpler', 'simpli', 'simpson', 'simul', 'sinc', 'sinco', 'sindu', 'sing', 'singapor', 'singl', 'sink', 'sip', 'sipix', 'sir', 'siri', 'sirjii', 'sirsalam', 'sister', 'sit', 'site', 'sitll', 'sitter', 'sittin', 'situat', 'siva', 'sivatat', 'six', 'size', 'sk3', 'sk38xh', 'skalli', 'skateboard', 'ski', 'skilgm', 'skill', 'skillgam', 'skillgame1winaweek', 'skin', 'skinni', 'skint', 'skip', 'skirt', 'sky', 'skye', 'skype', 'skyve', 'slaaaaav', 'slack', 'slap', 'slave', 'sleep', 'sleepi', 'sleepin', 'sleepingand', 'sleepingwith', 'sleepsweet', 'sleepwellamptak', 'slept', 'slice', 'slide', 'slightli', 'slip', 'slipper', 'slipperi', 'slo', 'slo4msg', 'slob', 'slot', 'slove', 'slow', 'slower', 'slowli', 'slurp', 'sm', 'smack', 'small', 'smaller', 'smart', 'smartcal', 'smarter', 'smartthough', 'smash', 'smear', 'smell', 'smeon', 'smidgin', 'smile', 'smiley', 'smith', 'smithswitch', 'smoke', 'smokin', 'smoothli', 'sms08718727870', 'smsd', 'smsing', 'smsservic', 'smsshsexnetun', 'smth', 'sn', 'snake', 'snap', 'snappi', 'snatch', 'snd', 'sneham', 'snicker', 'sno', 'snog', 'snoringthey', 'snow', 'snowbal', 'snowboard', 'snowman', 'snuggl', 'so', 'soani', 'soc', 'socht', 'social', 'sofa', 'soft', 'softwar', 'soil', 'soire', 'sol', 'soladha', 'sold', 'solihul', 'solv', 'some', 'some1', 'somebodi', 'someday', 'someon', 'someonethat', 'someonon', 'someplac', 'somerset', 'someth', 'somethin', 'sometim', 'sometimerakheshvisitor', 'sometm', 'somewhat', 'somewher', 'somewheresomeon', 'somewhr', 'somon', 'somtim', 'sonathaya', 'sonetim', 'song', 'soni', 'sonot', 'sonyericsson', 'soo', 'soon', 'soonc', 'sooner', 'soonlot', 'soonxxx', 'sooo', 'soooo', 'sooooo', 'sopha', 'sore', 'sori', 'sorri', 'sorrow', 'sorrowsi', 'sorryi', 'sorryin', 'sort', 'sorta', 'sortedbut', 'sorydarealyfrm', 'soso', 'soul', 'sound', 'soundtrack', 'soup', 'sourc', 'south', 'southern', 'souveni', 'soz', 'space', 'spacebuck', 'spageddi', 'spain', 'spam', 'spanish', 'spare', 'spark', 'sparkl', 'spatula', 'speak', 'spec', 'special', 'specialcal', 'specialis', 'specif', 'specifi', 'speechless', 'speed', 'speedchat', 'spele', 'spell', 'spend', 'spent', 'spi', 'spice', 'spider', 'spiderman', 'spif', 'spile', 'spin', 'spinout', 'spiral', 'spirit', 'spiritu', 'spjanuari', 'spk', 'spl', 'splash', 'splashmobil', 'splat', 'splendid', 'split', 'splle', 'splwat', 'spoil', 'spoilt', 'spoke', 'spoken', 'sponsor', 'spontan', 'spook', 'spoon', 'sporad', 'sport', 'sportsx', 'spose', 'spot', 'spotti', 'spous', 'sppok', 'spreadsheet', 'spree', 'spring', 'sprint', 'sprwm', 'sptv', 'sptyron', 'spunout', 'sq825', 'squat', 'squeeeeez', 'squeez', 'squid', 'squishi', 'sr', 'sri', 'srsli', 'srt', 'ssi', 'ssindia', 'ssnervou', 'st', 'stabil', 'stabl', 'stadium', 'staff', 'staffsciencenusedusgphyhcmkteachingpc1323', 'stage', 'stagwood', 'stair', 'stalk', 'stamp', 'stand', 'standard', 'stapati', 'star', 'stare', 'starer', 'starshin', 'start', 'startedindia', 'starti', 'starv', 'starwars3', 'stash', 'state', 'statement', 'station', 'statu', 'stay', 'stayin', 'std', 'stdtxtrate', 'steak', 'steal', 'steam', 'steamboat', 'steed', 'steer', 'step', 'stereo', 'stereophon', 'sterl', 'sterm', 'steve', 'stevelik', 'stewarts', 'steyn', 'sth', 'sthi', 'stick', 'sticki', 'stifl', 'stil', 'still', 'stillmayb', 'stink', 'stitch', 'stock', 'stockport', 'stolen', 'stomach', 'stomp', 'stone', 'stoner', 'stool', 'stop', 'stop2', 'stop2stop', 'stopbcm', 'stopc', 'stopcost', 'stoptxt', 'stoptxtstop', 'store', 'storelik', 'stori', 'storm', 'str', 'str8', 'straight', 'strain', 'strang', 'stranger', 'strangersaw', 'stream', 'street', 'streetshal', 'stress', 'stressful', 'stretch', 'strewn', 'strict', 'strike', 'string', 'strip', 'stripe', 'stroke', 'strong', 'strongbuy', 'strongli', 'strt', 'strtd', 'struggl', 'stu', 'stubborn', 'stuck', 'studdi', 'student', 'studentfinanci', 'studentsthi', 'studi', 'studio', 'studyn', 'stuf', 'stuff', 'stuff42moro', 'stuffleav', 'stuffwhi', 'stun', 'stupid', 'stupidit', 'style', 'stylish', 'stylist', 'sub', 'subject', 'sublet', 'submit', 'subpoli', 'subscrib', 'subscribe6gbpmnth', 'subscript', 'subscriptn3gbpwk', 'subscrit', 'subsequ', 'subtoitl', 'success', 'such', 'suck', 'sucker', 'sudden', 'suddenli', 'sudn', 'sue', 'suffer', 'suffici', 'sugabab', 'suganya', 'sugar', 'sugardad', 'suggest', 'suit', 'suitem', 'sullivan', 'sum', 'sum1', 'sumf', 'summer', 'summon', 'sumthin', 'sumthinxx', 'sun', 'sun0819', 'sunday', 'sundayish', 'sunlight', 'sunni', 'sunoco', 'sunroof', 'sunscreen', 'sunshin', 'suntec', 'sup', 'super', 'superb', 'superior', 'supervisor', 'supli', 'supos', 'suppli', 'supplier', 'support', 'supportprovid', 'supportveri', 'suppos', 'suprem', 'suprman', 'sura', 'sure', 'surf', 'surgic', 'surli', 'surnam', 'surpris', 'surrend', 'surround', 'survey', 'surya', 'sutra', 'sux', 'suzi', 'svc', 'sw7', 'sw73ss', 'swalpa', 'swan', 'swann', 'swap', 'swashbuckl', 'swat', 'swatch', 'sway', 'swayz', 'swear', 'sweater', 'sweatter', 'sweet', 'sweetest', 'sweetheart', 'sweeti', 'swell', 'swhrt', 'swim', 'swimsuit', 'swing', 'swiss', 'switch', 'swollen', 'swoop', 'swt', 'swtheart', 'syd', 'syllabu', 'symbol', 'sympathet', 'symptom', 'sync', 'syria', 'syrup', 'system', 't91', 'ta', 'tabl', 'tablet', 'tackl', 'taco', 'tact', 'tactless', 'tadaaaaa', 'tag', 'tahan', 'tai', 'tait', 'taj', 'taka', 'take', 'takecar', 'taken', 'takenonli', 'takin', 'talent', 'talk', 'talkbut', 'talkin', 'tall', 'tallahasse', 'tallent', 'tamilnaduthen', 'tampa', 'tank', 'tantrum', 'tap', 'tape', 'tariff', 'tarot', 'tarpon', 'tast', 'tat', 'tata', 'tattoo', 'tau', 'taught', 'taunton', 'tax', 'taxi', 'taxless', 'taxt', 'taylor', 'tayseertissco', 'tb', 'tbspersolvo', 'tc', 'tcllc', 'tcrw1', 'tcsbcm4235wc1n3xx', 'tcsc', 'tcsstop', 'tddnewsletteremc1couk', 'tea', 'teach', 'teacher', 'teacoffe', 'team', 'tear', 'teas', 'tech', 'technic', 'technolog', 'tee', 'teenag', 'teeth', 'teethi', 'teethif', 'teju', 'tel', 'telephon', 'teletext', 'tell', 'telli', 'tellmiss', 'telphon', 'telugu', 'telugutht', 'temal', 'temp', 'temper', 'templ', 'ten', 'tenant', 'tendenc', 'tenerif', 'tens', 'tension', 'teresa', 'term', 'terminatedw', 'termsappli', 'terri', 'terribl', 'terrif', 'terrorist', 'tesco', 'tessypl', 'test', 'tex', 'texa', 'texd', 'text', 'text82228', 'textand', 'textbook', 'textbuddi', 'textcomp', 'textin', 'textoper', 'textpod', 'textsweekend', 'tgxxrz', 'th', 'than', 'thandiyachu', 'thangam', 'thangamit', 'thank', 'thanks2', 'thanksgiv', 'thanku', 'thankyou', 'thanx', 'thanx4', 'thanxxx', 'thasa', 'that', 'that2worzel', 'thatd', 'thatdont', 'thati', 'thatll', 'thatmum', 'thatnow', 'the', 'the4th', 'theacus', 'theater', 'theatr', 'thecd', 'thedailydraw', 'thekingshead', 'them', 'theme', 'themob', 'themobhit', 'themobyo', 'themp', 'then', 'thenwil', 'theoret', 'theori', 'theplac', 'thepub', 'there', 'theredo', 'theregoodnight', 'therel', 'therer', 'therexx', 'these', 'theseday', 'theseyour', 'thesi', 'thesmszonecom', 'thewend', 'they', 'theyll', 'theyr', 'thgt', 'thi', 'thia', 'thin', 'thing', 'thinghow', 'think', 'thinkin', 'thinkthi', 'thinl', 'thirunelvali', 'thisdon', 'thk', 'thkin', 'thm', 'thnk', 'thnq', 'thnx', 'tho', 'those', 'thoso', 'thot', 'thou', 'though', 'thought', 'thoughtsi', 'thousand', 'thout', 'thread', 'threat', 'three', 'threw', 'thriller', 'throat', 'throw', 'throwin', 'thrown', 'thru', 'thrurespect', 'tht', 'thu', 'thuglyf', 'thur', 'thursday', 'thx', 'ti', 'tick', 'ticket', 'tiempo', 'tiger', 'tight', 'tightli', 'tigress', 'tih', 'tiim', 'til', 'till', 'tim', 'time', 'timedhoni', 'timegud', 'timehop', 'timeslil', 'timey', 'timeyour', 'timi', 'timin', 'tini', 'tip', 'tire', 'tirunelvai', 'tirunelvali', 'tirupur', 'tisscotays', 'titl', 'titleso', 'tiwari', 'tix', 'tiz', 'tke', 'tkt', 'tlk', 'tm', 'tming', 'tmobil', 'tmorrowpl', 'tmr', 'tmrw', 'tmw', 'tnc', 'toa', 'toaday', 'tobacco', 'tobe', 'tocallshal', 'toclaim', 'today', 'todaybut', 'todaydo', 'todayfrom', 'todaygood', 'todayh', 'todaysundaysunday', 'todo', 'tog', 'togeth', 'tohar', 'toilet', 'tok', 'toke', 'token', 'tol', 'told', 'toldsh', 'toledo', 'toler', 'toleratbc', 'toll', 'tom', 'tomarrow', 'tome', 'tomeandsaidthi', 'tomo', 'tomoc', 'tomorro', 'tomorrow', 'tomorrowcal', 'tomorrowtoday', 'tomorw', 'ton', 'tone', 'tones2u', 'tones2youcouk', 'tonesrepli', 'tonex', 'tonght', 'tongu', 'tonight', 'tonit', 'tonitebusi', 'toniteth', 'tonsolitusaswel', 'too', 'took', 'tookplac', 'tool', 'toolet', 'tooo', 'toopray', 'toot', 'toothpast', 'tootsi', 'top', 'topic', 'topicsorri', 'toplay', 'toppoli', 'tor', 'torch', 'torrent', 'tortilla', 'tortur', 'tosend', 'toshiba', 'toss', 'tot', 'total', 'tote', 'touch', 'tough', 'toughest', 'tour', 'toward', 'town', 'towncud', 'towndontmatt', 'toxic', 'toyota', 'tp', 'track', 'trackmarqu', 'trade', 'tradit', 'traffic', 'train', 'trainner', 'tram', 'tranquil', 'transact', 'transcrib', 'transfer', 'transferacc', 'transfr', 'transport', 'trash', 'trauma', 'trav', 'travel', 'treacl', 'treadmil', 'treasur', 'treat', 'treatin', 'trebl', 'tree', 'trek', 'trend', 'tri', 'trial', 'trip', 'tripl', 'trishul', 'triumph', 'tron', 'troubl', 'troubleshoot', 'trouser', 'trubl', 'truck', 'true', 'truekdo', 'truffl', 'truli', 'truro', 'trust', 'truth', 'tryin', 'trywal', 'ts', 'tsandc', 'tsc', 'tscs08714740323', 'tscs087147403231winawkage16', 'tshirt', 'tsunami', 'tt', 'ttyl', 'tue', 'tuesday', 'tui', 'tuition', 'tul', 'tulip', 'tund', 'tune', 'tunji', 'turkey', 'turn', 'tuth', 'tv', 'tvhe', 'tvlol', 'twat', 'twelv', 'twenti', 'twice', 'twigg', 'twilight', 'twin', 'twink', 'twitter', 'two', 'txt', 'txt250com', 'txtauction', 'txtauctiontxt', 'txtin', 'txting', 'txtjourney', 'txtno', 'txtx', 'tyler', 'type', 'typelyk', 'typic', 'u', 'u2moro', 'uawakefeellikw', 'ubandu', 'ubi', 'ucal', 'ufind', 'ugadi', 'ugh', 'ugo', 'uh', 'uhhhhrmm', 'uif', 'uin', 'ujhhhhhhh', 'uk', 'ukmobiled', 'ukp2000', 'ull', 'ultim', 'ultimatum', 'um', 'umma', 'ummmawil', 'ummmmmaah', 'un', 'unabl', 'unbeliev', 'uncl', 'unclaim', 'uncomfort', 'uncondit', 'unconsci', 'unconvinc', 'uncount', 'uncut', 'under', 'underdtand', 'understand', 'understood', 'underwear', 'undrstnd', 'undrstndng', 'unemploy', 'unev', 'unfold', 'unfortun', 'unfortuntli', 'unhappi', 'uni', 'unicef', 'uniform', 'unintent', 'uniqu', 'uniquei', 'unit', 'univ', 'univers', 'unknown', 'unless', 'unlik', 'unlimit', 'unmit', 'unnecessarili', 'unni', 'unrecogn', 'unredeem', 'unsecur', 'unsold', 'unsoldmik', 'unsoldnow', 'unspoken', 'unsub', 'unsubscrib', 'until', 'unusu', 'uothrwis', 'up', 'up4', 'upcharg', 'upd8', 'updat', 'updatenow', 'upgrad', 'upgrdcentr', 'uphad', 'upload', 'upnot', 'upon', 'upset', 'upseti', 'upsetit', 'upstair', 'upto', 'uptown', 'upyeh', 'ur', 'ure', 'urfeel', 'urgent', 'urgentbut', 'urgentlyit', 'urgh', 'urgnt', 'urgoin', 'urgran', 'urin', 'url', 'urmomi', 'urn', 'urself', 'us', 'usb', 'usc', 'uscedu', 'use', 'useless', 'user', 'usf', 'usget', 'usher', 'uslet', 'usml', 'usno', 'uso', 'usp', 'usual', 'usualiam', 'uteru', 'utter', 'uup', 'uv', 'uve', 'uwana', 'uwant', 'uworld', 'uxxxx', 'v', 'vaazhthukk', 'vagu', 'vai', 'vale', 'valentin', 'valid', 'valid12hr', 'valu', 'valuabl', 'valuemorn', 'varaya', 'vargu', 'vari', 'variou', 'varma', 'vasai', 'vat', 'vatian', 'vava', 'vco', 'vday', 'vega', 'veget', 'veggi', 'vehicl', 'velacheri', 'velli', 'velusami', 'venaam', 'venugop', 'veri', 'verifi', 'version', 'versu', 'vettam', 'vewi', 'via', 'vibrant', 'vibrat', 'vic', 'victor', 'victoria', 'vid', 'video', 'videochat', 'videop', 'videophon', 'videosound', 'videosounds2', 'vidnot', 'view', 'vijay', 'vijaykanth', 'vikki', 'vikkyim', 'vilikkamt', 'vill', 'villa', 'villag', 'vinobanagar', 'violat', 'violenc', 'violet', 'vip', 'virgil', 'virgin', 'virtual', 'visa', 'visionsmscom', 'visit', 'visitne', 'visitor', 'vital', 'vitamin', 'viva', 'vivek', 'vivekanand', 'viveki', 'vl', 'vldo', 'voda', 'vodafon', 'vodka', 'voic', 'voicemail', 'voila', 'volcano', 'vomit', 'vomitin', 'vote', 'voucher', 'voucherstext', 'vpist', 'vpod', 'vri', 'vs', 'vth', 'vtire', 'w', 'w111wx', 'w14rg', 'w1a', 'w1j', 'w1t1ji', 'w45wq', 'w8in', 'wa', 'wa14', 'waaaat', 'wad', 'wadebridgei', 'wah', 'wahala', 'wahay', 'wahe', 'waheeda', 'wahleykkumshar', 'waht', 'wait', 'waiti', 'waitin', 'waitshould', 'waitu', 'wake', 'wale', 'walik', 'walk', 'walkabout', 'walkin', 'wall', 'wallet', 'wallpap', 'wallpaperal', 'walmart', 'walsal', 'wamma', 'wan', 'wan2', 'wana', 'wanna', 'wannatel', 'want', 'want2com', 'wap', 'waqt', 'warm', 'warn', 'warner', 'warranti', 'warwick', 'washob', 'wasnt', 'wast', 'wat', 'watch', 'watchin', 'watchng', 'wate', 'water', 'watev', 'watevr', 'watll', 'watrdayno', 'watt', 'wave', 'way', 'way2smscom', 'waythi', 'wc', 'wc1n', 'wc1n3xx', 'weak', 'weapon', 'wear', 'weasel', 'weather', 'web', 'web2mobil', 'webadr', 'webeburnin', 'webpag', 'websit', 'websitenow', 'wed', 'weddin', 'weddingfriend', 'wedlunch', 'wednesday', 'wee', 'weed', 'weeddefici', 'week', 'weekday', 'weekend', 'weekli', 'weekstop', 'weigh', 'weight', 'weighthaha', 'weightloss', 'weird', 'weirdest', 'weirdi', 'weirdo', 'weiyi', 'welcom', 'well', 'wellda', 'welli', 'welltak', 'wellyou', 'welp', 'wen', 'wendi', 'wenev', 'went', 'wenwecan', 'wer', 'were', 'werear', 'werebor', 'werent', 'wereth', 'wesley', 'west', 'western', 'westlif', 'westonzoyland', 'westshor', 'wet', 'wetherspoon', 'weve', 'wewa', 'whassup', 'what', 'whatev', 'whatsup', 'wheat', 'wheel', 'wheellock', 'when', 'whenev', 'whenevr', 'whenr', 'whenwher', 'where', 'wherear', 'wherebtw', 'wherev', 'wherevr', 'wherr', 'whether', 'whi', 'which', 'while', 'whileamp', 'whilltak', 'whisper', 'white', 'whn', 'who', 'whole', 'whom', 'whore', 'whose', 'whr', 'wi', 'wick', 'wicket', 'wicklow', 'wid', 'widelivecomindex', 'wif', 'wife', 'wifedont', 'wifehow', 'wifi', 'wihtuot', 'wikipediacom', 'wil', 'wild', 'wildest', 'wildlif', 'will', 'willpow', 'win', 'win150ppmx3age16', 'wind', 'windi', 'window', 'wine', 'wing', 'winner', 'winnersclub', 'winterston', 'wipe', 'wipro', 'wiproy', 'wire3net', 'wisdom', 'wise', 'wish', 'wishin', 'wishlist', 'wiskey', 'wit', 'with', 'withdraw', 'wither', 'within', 'without', 'witin', 'witot', 'witout', 'wiv', 'wizzl', 'wk', 'wkend', 'wkent150p16', 'wkg', 'wkli', 'wknd', 'wktxt', 'wlcome', 'wld', 'wmlid1b6a5ecef91ff937819firsttrue180430jul05', 'wmlid820554ad0a1705572711firsttru', 'wnevr', 'wnt', 'wo', 'woah', 'wocay', 'woke', 'woken', 'woman', 'womdarful', 'women', 'won', 'wondar', 'wondarful', 'wonder', 'wont', 'woo', 'wood', 'woodland', 'woohoo', 'woot', 'woould', 'woozl', 'worc', 'word', 'wordcollect', 'wordnot', 'wordsevri', 'wordstart', 'work', 'workag', 'workand', 'workin', 'worklov', 'workout', 'world', 'worldgnun', 'worldmay', 'worldveri', 'worm', 'worri', 'worriedx', 'worryc', 'worryus', 'wors', 'worst', 'worth', 'worthless', 'wot', 'wotu', 'wotz', 'woul', 'would', 'woulda', 'wouldnt', 'wound', 'wow', 'wquestion', 'wrc', 'wreck', 'wrench', 'wright', 'write', 'writh', 'wrk', 'wrki', 'wrkin', 'wrking', 'wrld', 'wrnog', 'wrong', 'wrongli', 'wrongtak', 'wrote', 'ws', 'wt', 'wtc', 'wtf', 'wth', 'wthout', 'wud', 'wudnt', 'wuld', 'wuldnt', 'wun', 'www07781482378com', 'www4tcbiz', 'www80488biz', 'wwwapplausestorecom', 'wwwareyouuniquecouk', 'wwwasjesuscom', 'wwwb4utelecom', 'wwwbridalpetticoatdreamscouk', 'wwwcashbincouk', 'wwwclubmobycom', 'wwwclubzedcouk', 'wwwcnupdatescomnewslett', 'wwwcomuknet', 'wwwdbuknet', 'wwwflirtpartyu', 'wwwfullonsmscom', 'wwwgambtv', 'wwwgetzedcouk', 'wwwidewcom', 'wwwldewcom', 'wwwldewcom1win150ppmx3age16', 'wwwldewcom1win150ppmx3age16subscript', 'wwwldewcomsubs161win150ppmx3', 'wwwmovietriviatv', 'wwwmusictrivianet', 'wwworangecoukow', 'wwwphb1com', 'wwwregalportfoliocouk', 'wwwringtonekingcouk', 'wwwringtonescouk', 'wwwrtfsphostingcom', 'wwwsantacallingcom', 'wwwshortbreaksorguk', 'wwwsmsacubootydeli', 'wwwsmsacugoldvik', 'wwwsmsacuhmmross', 'wwwsmsacunat27081980', 'wwwsmsacunatalie2k9', 'wwwsmsconet', 'wwwtcbiz', 'wwwtelediscountcouk', 'wwwtextcompcom', 'wwwtextpodnet', 'wwwtklscom', 'wwwtxt2shopcom', 'wwwtxt43com', 'wwwtxt82228com', 'wwwtxttowincouk', 'wwwwin82050couk', 'wyli', 'x', 'x29', 'x49', 'x49your', 'xafter', 'xam', 'xavier', 'xchat', 'xclusiveclubsaisai', 'xin', 'xma', 'xnet', 'xoxo', 'xt', 'xuhui', 'xx', 'xxsp', 'xxuk', 'xxx', 'xxxmobilemovieclub', 'xxxmobilemovieclubcomnqjkgighjjgcbl', 'xxxx', 'xxxxx', 'xxxxxx', 'xxxxxxx', 'xxxxxxxx', 'xxxxxxxxxxxxxx', 'xy', 'y87', 'ya', 'yago', 'yah', 'yahoo', 'yalrigu', 'yalru', 'yam', 'yan', 'yar', 'yard', 'yavnt', 'yaxx', 'yaxxx', 'yay', 'yck', 'yday', 'ye', 'yeah', 'yeahand', 'year', 'yeesh', 'yeh', 'yell', 'yellow', 'yelowi', 'yen', 'yeovil', 'yep', 'yer', 'yes165', 'yes434', 'yes440', 'yes762', 'yes910', 'yesbut', 'yesfrom', 'yesgauti', 'yesh', 'yesher', 'yesim', 'yesmum', 'yessura', 'yest', 'yesterday', 'yet', 'yetti', 'yetund', 'yi', 'yifeng', 'yiju', 'yijuehotmailcom', 'ym', 'ymca', 'yo', 'yoga', 'yogasana', 'yoher', 'yor', 'yorg', 'you', 'youani', 'youcarlo', 'youclean', 'youd', 'youdearwith', 'youdo', 'youhow', 'youi', 'youkwher', 'yould', 'youll', 'youmi', 'youmoney', 'young', 'younger', 'youphon', 'your', 'yourinclus', 'yourjob', 'yourself', 'youso', 'youthat', 'youto', 'youuuuu', 'youv', 'youwanna', 'youwhen', 'yovil', 'yowif', 'yoyyooo', 'yr', 'ystrdayic', 'yummi', 'yummmm', 'yun', 'yunni', 'yuo', 'yuou', 'yup', 'yupz', 'ywhere', 'zac', 'zaher', 'zealand', 'zebra', 'zed', 'zero', 'zhong', 'zindgi', 'zoe', 'zogtoriu', 'zoom', 'zouk', 'zyada', 'Ü', 'é', 'ü', 'üll', '〨ud']\n"
     ]
    }
   ],
   "source": [
    "print(cv1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 131)\n"
     ]
    }
   ],
   "source": [
    "data_sample = data[0:10]\n",
    "\n",
    "cv2 = CountVectorizer(analyzer=clean_text)\n",
    "\n",
    "X = cv2.fit_transform(data_sample['msg'])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>08002986030</th>\n",
       "      <th>08452810075over18</th>\n",
       "      <th>09061701461</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>150</th>\n",
       "      <th>2</th>\n",
       "      <th>2005</th>\n",
       "      <th>21st</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>vettam</th>\n",
       "      <th>wat</th>\n",
       "      <th>week</th>\n",
       "      <th>wif</th>\n",
       "      <th>win</th>\n",
       "      <th>winner</th>\n",
       "      <th>wkli</th>\n",
       "      <th>word</th>\n",
       "      <th>world</th>\n",
       "      <th>xxx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   08002986030  08452810075over18  09061701461  11  12  150  2  2005  21st  3  \\\n",
       "0            0                  0            0   0   0    0  0     0     0  0   \n",
       "1            0                  0            0   0   0    0  0     0     0  0   \n",
       "2            0                  1            0   0   0    0  1     1     1  0   \n",
       "3            0                  0            0   0   0    0  0     0     0  0   \n",
       "4            0                  0            0   0   0    0  0     0     0  0   \n",
       "5            0                  0            0   0   0    1  0     0     0  1   \n",
       "6            0                  0            0   0   0    0  0     0     0  0   \n",
       "7            0                  0            0   0   0    0  0     0     0  0   \n",
       "8            0                  0            1   0   1    0  0     0     0  0   \n",
       "9            1                  0            0   1   0    0  0     0     0  0   \n",
       "\n",
       "   ...  vettam  wat  week  wif  win  winner  wkli  word  world  xxx  \n",
       "0  ...       0    1     0    0    0       0     0     0      1    0  \n",
       "1  ...       0    0     0    1    0       0     0     0      0    0  \n",
       "2  ...       0    0     0    0    1       0     1     0      0    0  \n",
       "3  ...       0    0     0    0    0       0     0     0      0    0  \n",
       "4  ...       0    0     0    0    0       0     0     0      0    0  \n",
       "5  ...       0    0     1    0    0       0     0     1      0    1  \n",
       "6  ...       0    0     0    0    0       0     0     0      0    0  \n",
       "7  ...       1    0     0    0    0       0     0     0      0    0  \n",
       "8  ...       0    0     0    0    0       1     0     0      0    0  \n",
       "9  ...       0    0     0    0    0       0     0     0      0    0  \n",
       "\n",
       "[10 rows x 131 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X.toarray(), columns = cv2.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-Grams creates a document-term matrix where:\n",
    "- columns represent all columns of adjacent words of length \"**n**\"\n",
    "- cells represent count\n",
    "\n",
    "         Ex.: \"I am studying NLP\"\n",
    "\n",
    "**bigram**: \"I am\", \"am studying\", \"studying NLP\"\n",
    "\n",
    "**trigram**: \"I am studying\", \"am studying NLP\"\n",
    "\n",
    "**4-gram**: \"I am studying NLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 5)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 7)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 7)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 6)\t1\n",
      "[[0 0 0 0 1 1 0 1]\n",
      " [1 0 1 0 0 0 0 1]\n",
      " [0 1 0 1 0 0 1 0]]\n",
      "   another sentence  document is  is another  is here  is sentence  \\\n",
      "0                 0            0           0        0            1   \n",
      "1                 1            0           1        0            0   \n",
      "2                 0            1           0        1            0   \n",
      "\n",
      "   sentence is  third document  this is  \n",
      "0            1               0        1  \n",
      "1            0               0        1  \n",
      "2            0               1        0  \n"
     ]
    }
   ],
   "source": [
    "# Calling the CountVectorizer function, but now passing the \"ngrams\" to use\n",
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "corpus = [\"This is a sentence is\",\n",
    "         \"This is another sentence\",\n",
    "         \"third document is here\"]\n",
    "\n",
    "X = cv.fit_transform(corpus)\n",
    "\n",
    "print(X.shape, type(X))\n",
    "print(X)\n",
    "print(X.toarray())\n",
    "\n",
    "df = pd.DataFrame(X.toarray(), columns = cv.get_feature_names())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 24)\n",
      "   another  another sentence  document  document is  document is here  here  \\\n",
      "0        0                 0         0            0                 0     0   \n",
      "1        1                 1         0            0                 0     0   \n",
      "2        0                 0         1            1                 1     1   \n",
      "\n",
      "   is  is another  is another sentence  is here  ...  third  third document  \\\n",
      "0   2           0                    0        0  ...      0               0   \n",
      "1   1           1                    1        0  ...      0               0   \n",
      "2   1           0                    0        1  ...      1               1   \n",
      "\n",
      "   third document is  third document is here  this  this is  this is another  \\\n",
      "0                  0                       0     1        1                0   \n",
      "1                  0                       0     1        1                1   \n",
      "2                  1                       1     0        0                0   \n",
      "\n",
      "   this is another sentence  this is sentence  this is sentence is  \n",
      "0                         0                 1                    1  \n",
      "1                         1                 0                    0  \n",
      "2                         0                 0                    0  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,4))\n",
    "X = cv.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "df = pd.DataFrame(X.toarray(), columns = cv.get_feature_names())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams CountVectorization on SMSSpamCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>Go jurong point crazi avail bugi n great world la e buffet cine got amor wat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>free entri 2 wkli comp win FA cup final tkt 21st may 2005 text FA 87121 receiv entri questionstd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say earli hor U c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>nah I dont think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                             msg_clean  \n",
       "0                         Go jurong point crazi avail bugi n great world la e buffet cine got amor wat  \n",
       "1                                                                                Ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win FA cup final tkt 21st may 2005 text FA 87121 receiv entri questionstd...  \n",
       "3                                                                  U dun say earli hor U c alreadi say  \n",
       "4                                                          nah I dont think goe usf live around though  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the Text Cleaning function\n",
    "# Adding \" \".join() at the 3rd line\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = \" \".join([ps.stem(word) for word in tokens if word not in stopwords])\n",
    "    return text\n",
    "\n",
    "data['msg_clean'] = data['msg'].apply(lambda x: clean_text(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Note that **msg_clean** column contains a clean text, but **it is a sentence now**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 34162)\n"
     ]
    }
   ],
   "source": [
    "# Providing the \"ngrams\" parameter\n",
    "cv1 = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "X = cv1.fit_transform(data['msg_clean'])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 71)\n"
     ]
    }
   ],
   "source": [
    "# Providing the \"ngrams\" parameter AND an analyzer function instead of the default one\n",
    "cv1 = CountVectorizer(analyzer=clean_text, ngram_range=(2,2))\n",
    "\n",
    "X = cv1.fit_transform(data['msg'])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 126)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>09061701461 claim</th>\n",
       "      <th>11 month</th>\n",
       "      <th>12 hour</th>\n",
       "      <th>150 rcv</th>\n",
       "      <th>2005 text</th>\n",
       "      <th>21st may</th>\n",
       "      <th>87121 receiv</th>\n",
       "      <th>900 prize</th>\n",
       "      <th>aid patent</th>\n",
       "      <th>alreadi say</th>\n",
       "      <th>...</th>\n",
       "      <th>valu network</th>\n",
       "      <th>vettam set</th>\n",
       "      <th>week word</th>\n",
       "      <th>wif oni</th>\n",
       "      <th>win fa</th>\n",
       "      <th>winner as</th>\n",
       "      <th>wkli comp</th>\n",
       "      <th>word back</th>\n",
       "      <th>world la</th>\n",
       "      <th>xxx std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   09061701461 claim  11 month  12 hour  150 rcv  2005 text  21st may  \\\n",
       "0                  0         0        0        0          0         0   \n",
       "1                  0         0        0        0          0         0   \n",
       "2                  0         0        0        0          1         1   \n",
       "3                  0         0        0        0          0         0   \n",
       "4                  0         0        0        0          0         0   \n",
       "5                  0         0        0        1          0         0   \n",
       "6                  0         0        0        0          0         0   \n",
       "7                  0         0        0        0          0         0   \n",
       "8                  1         0        1        0          0         0   \n",
       "9                  0         1        0        0          0         0   \n",
       "\n",
       "   87121 receiv  900 prize  aid patent  alreadi say  ...  valu network  \\\n",
       "0             0          0           0            0  ...             0   \n",
       "1             0          0           0            0  ...             0   \n",
       "2             1          0           0            0  ...             0   \n",
       "3             0          0           0            1  ...             0   \n",
       "4             0          0           0            0  ...             0   \n",
       "5             0          0           0            0  ...             0   \n",
       "6             0          0           1            0  ...             0   \n",
       "7             0          0           0            0  ...             0   \n",
       "8             0          1           0            0  ...             1   \n",
       "9             0          0           0            0  ...             0   \n",
       "\n",
       "   vettam set  week word  wif oni  win fa  winner as  wkli comp  word back  \\\n",
       "0           0          0        0       0          0          0          0   \n",
       "1           0          0        1       0          0          0          0   \n",
       "2           0          0        0       1          0          1          0   \n",
       "3           0          0        0       0          0          0          0   \n",
       "4           0          0        0       0          0          0          0   \n",
       "5           0          1        0       0          0          0          1   \n",
       "6           0          0        0       0          0          0          0   \n",
       "7           1          0        0       0          0          0          0   \n",
       "8           0          0        0       0          1          0          0   \n",
       "9           0          0        0       0          0          0          0   \n",
       "\n",
       "   world la  xxx std  \n",
       "0         1        0  \n",
       "1         0        0  \n",
       "2         0        0  \n",
       "3         0        0  \n",
       "4         0        0  \n",
       "5         0        1  \n",
       "6         0        0  \n",
       "7         0        0  \n",
       "8         0        0  \n",
       "9         0        0  \n",
       "\n",
       "[10 rows x 126 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample = data[0:10]\n",
    "\n",
    "# cv2 = CountVectorizer(analyzer=clean_text, ngram_range=(2,2))\n",
    "cv2 = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "X = cv2.fit_transform(data_sample['msg_clean'])\n",
    "print(X.shape)\n",
    "\n",
    "df = pd.DataFrame(X.toarray(), columns = cv2.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a document-term matrix where:\n",
    "- columns are individual unique words\n",
    "- cells contain a weight which signifies how important a word is for an individual text message\n",
    "\n",
    "$w_{i,j} = tf_{i,j} \\times log \\left(\\frac{N}{df_i}\\right)$\n",
    "\n",
    "Where:\n",
    "\n",
    "$w_{i,j}$ -> weight of a term I in a document J\n",
    "\n",
    "$N$ -> Total number of documents in the Corpus\n",
    "\n",
    "$tf_{i,j}$ -> Number of times a term I occurs in a document J divided by total number of terms in J\n",
    "\n",
    "$df_i$ -> Number of documents which contain the term I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 6, 'is': 3, 'sentence': 4, 'another': 0, 'third': 5, 'document': 1, 'here': 2}\n",
      "['another', 'document', 'here', 'is', 'sentence', 'third', 'this']\n",
      "(3, 7) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 6)\t0.4760629392767929\n",
      "  (0, 4)\t0.4760629392767929\n",
      "  (0, 3)\t0.7394106813498714\n",
      "  (1, 6)\t0.4804583972923858\n",
      "  (1, 4)\t0.4804583972923858\n",
      "  (1, 3)\t0.3731188059313277\n",
      "  (1, 0)\t0.6317450542765208\n",
      "  (2, 5)\t0.546454011634009\n",
      "  (2, 3)\t0.3227445421804912\n",
      "  (2, 2)\t0.546454011634009\n",
      "  (2, 1)\t0.546454011634009\n",
      "[[0.         0.         0.         0.73941068 0.47606294 0.\n",
      "  0.47606294]\n",
      " [0.63174505 0.         0.         0.37311881 0.4804584  0.\n",
      "  0.4804584 ]\n",
      " [0.         0.54645401 0.54645401 0.32274454 0.         0.54645401\n",
      "  0.        ]]\n",
      "    another  document      here        is  sentence     third      this\n",
      "0  0.000000  0.000000  0.000000  0.739411  0.476063  0.000000  0.476063\n",
      "1  0.631745  0.000000  0.000000  0.373119  0.480458  0.000000  0.480458\n",
      "2  0.000000  0.546454  0.546454  0.322745  0.000000  0.546454  0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "corpus = [\"This is a sentence is\",\n",
    "         \"This is another sentence\",\n",
    "         \"third document is here\"]\n",
    "\n",
    "X = tfidf_vect.fit(corpus)\n",
    "print(X.vocabulary_)\n",
    "print(tfidf_vect.get_feature_names())\n",
    "\n",
    "X = tfidf_vect.transform(corpus)\n",
    "#X = tfidf.fit_transform(corpus)\n",
    "\n",
    "print(X.shape, type(X))\n",
    "print(X)\n",
    "print(X.toarray())\n",
    "\n",
    "df = pd.DataFrame(X.toarray(), columns = tfidf_vect.get_feature_names())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer on SMSSpamCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[Go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, FA, cup, final, tkt, 21st, may, 2005, text, FA, 87121, receiv,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, earli, hor, U, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, I, dont, think, goe, usf, live, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                             msg_clean  \n",
       "0        [Go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]  \n",
       "1                                                                         [Ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, 2, wkli, comp, win, FA, cup, final, tkt, 21st, may, 2005, text, FA, 87121, receiv,...  \n",
       "3                                                        [U, dun, say, earli, hor, U, c, alreadi, say]  \n",
       "4                                                [nah, I, dont, think, goe, usf, live, around, though]  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Cleaning\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([c for c in text if c not in string.punctuation])   # remove punctuation\n",
    "    tokens = re.split('\\W+', text)                                     # tokenize\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords] # remove stopwords and apply Porter Stemming\n",
    "    return text\n",
    "\n",
    "data['msg_clean'] = data['msg'].apply(lambda x: clean_text(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8340)\n"
     ]
    }
   ],
   "source": [
    "# Define an analyzer instead of the default one\n",
    "tfidf1 = TfidfVectorizer(analyzer=clean_text)\n",
    "\n",
    "X = tfidf1.fit_transform(data['msg'])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 131)\n"
     ]
    }
   ],
   "source": [
    "data_sample = data[0:10]\n",
    "\n",
    "tfidf2 = TfidfVectorizer(analyzer=clean_text)\n",
    "\n",
    "X = tfidf2.fit_transform(data_sample['msg'])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>08002986030</th>\n",
       "      <th>08452810075over18</th>\n",
       "      <th>09061701461</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>150</th>\n",
       "      <th>2</th>\n",
       "      <th>2005</th>\n",
       "      <th>21st</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>vettam</th>\n",
       "      <th>wat</th>\n",
       "      <th>week</th>\n",
       "      <th>wif</th>\n",
       "      <th>win</th>\n",
       "      <th>winner</th>\n",
       "      <th>wkli</th>\n",
       "      <th>word</th>\n",
       "      <th>world</th>\n",
       "      <th>xxx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193446</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193446</td>\n",
       "      <td>0.193446</td>\n",
       "      <td>0.193446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193446</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.193446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.231109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.231109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231109</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.231109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219673</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.21594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.21594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.21594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.187859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.187859</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   08002986030  08452810075over18  09061701461        11       12       150  \\\n",
       "0     0.000000           0.000000      0.00000  0.000000  0.00000  0.000000   \n",
       "1     0.000000           0.000000      0.00000  0.000000  0.00000  0.000000   \n",
       "2     0.000000           0.193446      0.00000  0.000000  0.00000  0.000000   \n",
       "3     0.000000           0.000000      0.00000  0.000000  0.00000  0.000000   \n",
       "4     0.000000           0.000000      0.00000  0.000000  0.00000  0.000000   \n",
       "5     0.000000           0.000000      0.00000  0.000000  0.00000  0.231109   \n",
       "6     0.000000           0.000000      0.00000  0.000000  0.00000  0.000000   \n",
       "7     0.000000           0.000000      0.00000  0.000000  0.00000  0.000000   \n",
       "8     0.000000           0.000000      0.21594  0.000000  0.21594  0.000000   \n",
       "9     0.187859           0.000000      0.00000  0.187859  0.00000  0.000000   \n",
       "\n",
       "          2      2005      21st         3  ...    vettam   wat      week  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.25  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.00  0.000000   \n",
       "2  0.193446  0.193446  0.193446  0.000000  ...  0.000000  0.00  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.00  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.00  0.000000   \n",
       "5  0.000000  0.000000  0.000000  0.231109  ...  0.000000  0.00  0.231109   \n",
       "6  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.00  0.000000   \n",
       "7  0.000000  0.000000  0.000000  0.000000  ...  0.219673  0.00  0.000000   \n",
       "8  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.00  0.000000   \n",
       "9  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.00  0.000000   \n",
       "\n",
       "        wif       win   winner      wkli      word  world       xxx  \n",
       "0  0.000000  0.000000  0.00000  0.000000  0.000000   0.25  0.000000  \n",
       "1  0.408248  0.000000  0.00000  0.000000  0.000000   0.00  0.000000  \n",
       "2  0.000000  0.193446  0.00000  0.193446  0.000000   0.00  0.000000  \n",
       "3  0.000000  0.000000  0.00000  0.000000  0.000000   0.00  0.000000  \n",
       "4  0.000000  0.000000  0.00000  0.000000  0.000000   0.00  0.000000  \n",
       "5  0.000000  0.000000  0.00000  0.000000  0.231109   0.00  0.231109  \n",
       "6  0.000000  0.000000  0.00000  0.000000  0.000000   0.00  0.000000  \n",
       "7  0.000000  0.000000  0.00000  0.000000  0.000000   0.00  0.000000  \n",
       "8  0.000000  0.000000  0.21594  0.000000  0.000000   0.00  0.000000  \n",
       "9  0.000000  0.000000  0.00000  0.000000  0.000000   0.00  0.000000  \n",
       "\n",
       "[10 rows x 131 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X.toarray(), columns = tfidf2.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new features of transforming existing features using domain knowledge of the data, that makes machine learning algorithm work better.\n",
    "\n",
    "Some examples of F.E.:\n",
    "\n",
    "- Length of documents\n",
    "- Average word size within a document\n",
    "- Use of punctuation in the text\n",
    "- Capitalization of words in a document\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying some transformations to data can make it work better\n",
    "\n",
    "- Power transformations ($x^2$, $\\sqrt{x}$, etc.)\n",
    "- Standardizing data\n",
    "- Normalization: bring different features to similar scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature: message length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Datasets/SMSSpamCollection', sep='\\t', header=None)\n",
    "data.columns = ['label', 'msg']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "   msg_len  \n",
       "0      111  \n",
       "1       29  \n",
       "2      155  \n",
       "3       49  \n",
       "4       61  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['msg_len'] = data['msg'].apply(lambda x: len(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature: punctuation usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_len</th>\n",
       "      <th>punctuation_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>111</td>\n",
       "      <td>8.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>20.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>155</td>\n",
       "      <td>3.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>12.244898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>61</td>\n",
       "      <td>3.278689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                   msg  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "   msg_len  punctuation_%  \n",
       "0      111       8.108108  \n",
       "1       29      20.689655  \n",
       "2      155       3.870968  \n",
       "3       49      12.244898  \n",
       "4       61       3.278689  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def punctuation_count(txt):\n",
    "    count = sum([1 for c in txt if c in string.punctuation])\n",
    "    return 100*count/len(txt)\n",
    "\n",
    "data['punctuation_%'] = data['msg'].apply(lambda x: punctuation_count(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot message lengths for spam and ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6521: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  alternative=\"'density'\", removal=\"3.1\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 250, 50)\n",
    "plt.hist(data[data['label'] == 'spam']['msg_len'], bins, label='spam', normed=True)\n",
    "plt.hist(data[data['label'] == 'ham']['msg_len'], bins, label='ham', normed=True)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: message length is a good feature to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot to evaluate punctuation percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 30, 50)\n",
    "plt.hist(data[data['label'] == 'spam']['punctuation_%'], bins, label='spam', normed=True)\n",
    "plt.hist(data[data['label'] == 'ham']['punctuation_%'], bins, label='ham', normed=True)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: punctuation percentage is NOT a good feature to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing each data point in a certain column to make the distribution look closer to a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tukey Transformation**\n",
    "\n",
    "$y = \\left\\{\\begin{matrix} x^\\lambda , \\lambda > 0\\\\ log(x) , \\lambda = 0\\\\ -(x^\\lambda) , \\lambda < 0 \\end{matrix}\\right.$\n",
    "\n",
    "**Box-Cox Transformation**\n",
    "\n",
    "$y = \\left\\{\\begin{matrix} \\frac{x^\\lambda - 1}{\\lambda} , \\lambda \\neq 0\\\\ log(x) , \\lambda = 0 \\end{matrix}\\right.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trasformation Process**\n",
    "\n",
    "- Determine range of exponents to test\n",
    "\n",
    "- Apply tranformations to each value of the chosen feature\n",
    "\n",
    "- Determine which transformation yields best distribution, e.g., plot histogram and pick which looks closer to a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 250, 50)\n",
    "plt.hist(data['msg_len'], bins)\n",
    "plt.title('Message Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: it is kind of bimodal distribution spread somewhat uniformly - not a candidate for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 50, 50)\n",
    "plt.hist(data['punctuation_%'], bins)\n",
    "plt.title('Punctuation %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: data has skewed distribution with a long right tail - it can be applied some transformation on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some power transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for k,v in enumerate([2, 3, 4, 5]):\n",
    "    plt.subplot(2,2,k+1)\n",
    "    plt.hist((data['punctuation_%'])**(1/v), bins=50)\n",
    "    plt.title(f'Transform = 1/{v}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Accuracy = \\frac{\\#(predicted correctly)}{\\#(observations}$\n",
    "\n",
    "$Precision = \\frac{\\#(predicted as Spam correctly)}{\\#(predicted as Spam}$\n",
    "\n",
    "$Recall = \\frac{\\#(predicted as Spam correctly)}{\\#(actually Spam}$\n",
    "\n",
    "$F1 = (\\frac{2}{Recall^{-1} + Precision^{-1}}) = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "363px",
    "width": "633px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
